{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20abde9-3ed7-4cfc-a267-850ad7cbdec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dev实验版 所以堆到一起 以上的代码实际中在另一个文件\n",
    "import pandas as pd\n",
    "from ProcessCode.DateDataGET import DateDataGET_Impl\n",
    "from ProcessCode.DateDataProcess import DateDataProcess_Impl\n",
    "\n",
    "# date_sel要处理成2024-01-01格式\n",
    "def get_merge_data(date_sel):\n",
    "    DateDataGET_Impl(date_sel) # 从数据库中获取每日新闻数据 \n",
    "    DateDataProcess_Impl(date_sel) # 处理每日新闻数据获得分类处理后的_processed和总评估处理后的total_result_pure_\n",
    "    \n",
    "    \n",
    "    model_CLS_name = \"mbert_BiLSTM_SelfAttention\" ###!!!\n",
    "    # 读取total_result_pure.csv文件并提取id列的前20条数据以及对应的total_rank字段\n",
    "    # 总评估处理后文件\n",
    "    total_result_file_name = f\"../MergeFiveDScore/{model_CLS_name}/total_result_{date_sel}_{model_CLS_name}.csv\"\n",
    "\n",
    "    # total_result = pd.read_csv('./datasets/total_result_pure.csv', encoding='utf-8')\n",
    "    total_result = pd.read_csv(total_result_file_name, encoding='utf-8')\n",
    "\n",
    "    # id_and_rank = total_result[['id', 'total_rank']].head(20)\n",
    "    id_and_rank = total_result[['id', 'total_rank']]\n",
    "\n",
    "    # 分类处理后文件\n",
    "    processed_data_file_name = f\"../datasets/{model_CLS_name}/news_{date_sel}_processed_{model_CLS_name}.csv\"\n",
    "\n",
    "    # news_data = pd.read_csv('./datasets/Data231202_processed.csv', encoding='utf-8')\n",
    "    news_data = pd.read_csv(processed_data_file_name, encoding='utf-8')\n",
    "\n",
    "    # 读取website_Rank_new_FIX.csv文件\n",
    "    website_rank = pd.read_csv('../T2WebsiteRank/website_Rank_new_FIX.csv', encoding='utf-8')\n",
    "\n",
    "    # 根据id列表在news_data中读取对应id的数据\n",
    "    merged_data = pd.merge(id_and_rank, news_data, on='id')\n",
    "\n",
    "    # 根据website_id读取website_Rank_new_FIX.csv文件中的url字段\n",
    "    merged_data = pd.merge(merged_data, website_rank, on='website_id')\n",
    "\n",
    "\n",
    "    # 对字符串类型的字段进行编码转换\n",
    "    def encode_utf8(value):\n",
    "        if isinstance(value, str):\n",
    "            return value.encode('utf-8').decode('utf-8')\n",
    "        return value\n",
    "\n",
    "    string_columns = ['url', 'request_url', 'response_url', 'category1', 'category2', 'title', 'abstract', 'body', 'images', 'md5']\n",
    "    merged_data[string_columns] = merged_data[string_columns].applymap(encode_utf8)\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "\n",
    "\n",
    "def get_data_MIXed_Impl(date_sel):\n",
    "    \n",
    "    merged_data = get_merge_data(date_sel)\n",
    "    # 将每个id对应的数据包装成json格式\n",
    "    result_json = []\n",
    "    for index, row in merged_data.iterrows():\n",
    "        data_dict = {\n",
    "            'artId': row['id'],\n",
    "            'total_rank': row['total_rank'],\n",
    "            'websiteUrl': row['url'],\n",
    "            'website_id': row['website_id'],\n",
    "            'request_url': row['request_url'],\n",
    "            'response_url': row['response_url'],\n",
    "            'artType': row['category1'],\n",
    "            # 'category2': row['category2'],\n",
    "            'artTitle': row['title'],\n",
    "            'abstract': row['abstract'],\n",
    "            'artContent': row['body'],\n",
    "            'artTime': row['pub_time'],\n",
    "            'cole_time': row['cole_time'],\n",
    "            'artImageUrl': row['images'],\n",
    "            'language_id': row['language_id'],\n",
    "            'md5': row['md5'],\n",
    "            'artCusId': 582,\n",
    "            # test\n",
    "            \"customer\": {\"cusId\": 582, \"cusName\": \"admin\",\n",
    "                         \"cusPass\": None,\n",
    "                         \"cusSpider\": \"\",\n",
    "                         \"cusAvatarUrl\": \"http://localhost:8080/img/Man.png\",\n",
    "                         \"cusStyle\": \"这个人很懒, 什么都没写\",\n",
    "                         \"cusGender\": 0,\n",
    "                         \"cusTime\": \"2024-03-14T21:53:09.000+0000\", \"cusLegal\": 0},\n",
    "            \"artFeature\": {\"afcId\": 710, \"afcArtId\": 20171864,\n",
    "                           \"afcLikeNum\": 0, \"afcDislikeNum\": 0,\n",
    "                           \"afcComNum\": 0, \"afcRepNum\": 0,\n",
    "                           \"afcReadNum\": 0,\n",
    "                           \"afcArtTime\": None},\n",
    "            \"cusArtBehavior\": None\n",
    "        }\n",
    "        result_json.append(data_dict)\n",
    "        return result_json\n",
    "\n",
    "\n",
    "def get_data_ByType_Impl(date_sel,artType,page,pageSize):\n",
    "    \n",
    "    merged_data = get_merge_data(date_sel)\n",
    "\n",
    "    \n",
    "    if artType != \"综合\":\n",
    "        # 筛选类别category1为“test”的数据\n",
    "        filtered_data = merged_data[merged_data['category1'] == artType]\n",
    "    else:\n",
    "        filtered_data = merged_data\n",
    "\n",
    "    # 读取时读全部 然后选择时按照pageSize进行选择显示\n",
    "    print(type(pageSize))\n",
    "    filtered_data = filtered_data.head(int(pageSize))\n",
    "\n",
    "    # 将每个id对应的数据包装成json格式\n",
    "    result_json = []\n",
    "    # for index, row in merged_data.iterrows():\n",
    "    for index, row in filtered_data.iterrows():\n",
    "        data_dict = {\n",
    "            'artId': row['id'],\n",
    "            'total_rank': row['total_rank'],\n",
    "            'websiteUrl': row['url'],\n",
    "            'website_id': row['website_id'],\n",
    "            'request_url': row['request_url'],\n",
    "            'response_url': row['response_url'],\n",
    "            'artType': row['category1'],\n",
    "            # 'category2': row['category2'],\n",
    "            'artTitle': row['title'],\n",
    "            'abstract': row['abstract'],\n",
    "            'artContent': row['body'],\n",
    "            'artTime': row['pub_time'],\n",
    "            'cole_time': row['cole_time'],\n",
    "            'artImageUrl': row['images'],\n",
    "            'language_id': row['language_id'],\n",
    "            'md5': row['md5'],\n",
    "            'artCusId': 582,\n",
    "            # test\n",
    "            \"customer\": {\"cusId\": 582, \"cusName\": \"admin\",\n",
    "                         \"cusPass\": None,\n",
    "                         \"cusSpider\": \"\",\n",
    "                         \"cusAvatarUrl\": \"http://localhost:8080/img/Man.png\",\n",
    "                         \"cusStyle\": \"这个人很懒, 什么都没写\",\n",
    "                         \"cusGender\": 0,\n",
    "                         \"cusTime\": \"2024-03-14T21:53:09.000+0000\", \"cusLegal\": 0},\n",
    "            \"artFeature\": {\"afcId\": 710, \"afcArtId\": 20171864,\n",
    "                           \"afcLikeNum\": 0, \"afcDislikeNum\": 0,\n",
    "                           \"afcComNum\": 0, \"afcRepNum\": 0,\n",
    "                           \"afcReadNum\": 0,\n",
    "                           \"afcArtTime\": None},\n",
    "            \"cusArtBehavior\": None\n",
    "        }\n",
    "        result_json.append(data_dict)\n",
    "\n",
    "    return result_json\n",
    "\n",
    "\n",
    "def get_Categorys_Impl(date_sel):\n",
    "    merged_data = get_merge_data(date_sel)\n",
    "\n",
    "    # # 统计category1不同类别的种类数\n",
    "    # category_counts = merged_data['category1'].value_counts().to_dict()\n",
    "\n",
    "    # 提取category1列并转换为列表，并去重\n",
    "    category_list = merged_data['category1'].unique().tolist()\n",
    "\n",
    "    # 在列表的最前面加入一个元素\"综合\"\n",
    "    category_list.insert(0, '综合')\n",
    "\n",
    "    return category_list\n",
    "\n",
    "\n",
    "def get_ArtMain(date_sel,artId):\n",
    "    \n",
    "    merged_data = get_merge_data(date_sel)\n",
    "\n",
    "    # 根据artId筛选数据\n",
    "    filtered_data = merged_data[merged_data['id'] == int(artId)]\n",
    "\n",
    "    # 将每个id对应的数据包装成json格式\n",
    "    \n",
    "    result_dict = {}\n",
    "    # for index, row in merged_data.iterrows():\n",
    "    for index, row in filtered_data.iterrows():\n",
    "        data_dict = {\n",
    "            'artId': row['id'],\n",
    "            'total_rank': row['total_rank'],\n",
    "            'websiteUrl': row['url'],\n",
    "            'website_id': row['website_id'],\n",
    "            'request_url': row['request_url'],\n",
    "            'response_url': row['response_url'],\n",
    "            'artType': row['category1'],\n",
    "            # 'category2': row['category2'],\n",
    "            'artTitle': row['title'],\n",
    "            'abstract': row['abstract'],\n",
    "            'artContent': row['body'],\n",
    "            'artTime': row['pub_time'],\n",
    "            'cole_time': row['cole_time'],\n",
    "            'artImageUrl': row['images'],\n",
    "            'language_id': row['language_id'],\n",
    "            'md5': row['md5'],\n",
    "            'artCusId': 582,\n",
    "            # test\n",
    "            \"customer\": {\"cusId\": 582, \"cusName\": \"admin\",\n",
    "                         \"cusPass\": None,\n",
    "                         \"cusSpider\": \"\",\n",
    "                         \"cusAvatarUrl\": \"http://localhost:8080/img/Man.png\",\n",
    "                         \"cusStyle\": \"这个人很懒, 什么都没写\",\n",
    "                         \"cusGender\": 0,\n",
    "                         \"cusTime\": \"2024-03-14T21:53:09.000+0000\", \"cusLegal\": 0},\n",
    "            \"artFeature\": {\"afcId\": 710, \"afcArtId\": 20171864,\n",
    "                           \"afcLikeNum\": 0, \"afcDislikeNum\": 0,\n",
    "                           \"afcComNum\": 0, \"afcRepNum\": 0,\n",
    "                           \"afcReadNum\": 0,\n",
    "                           \"afcArtTime\": None},\n",
    "            \"cusArtBehavior\": None\n",
    "        }\n",
    "\n",
    "        result_dict = data_dict\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# 右侧推荐新闻处 随机返回pageSize条新闻\n",
    "def get_randomArt_Impl(date_sel,page,pageSize):\n",
    "    \n",
    "    merged_data = get_merge_data(date_sel)\n",
    "\n",
    "        \n",
    "    # 随机选取数据\n",
    "    # print(min(int(pageSize), len(merged_data)))\n",
    "    sample_data = merged_data.sample(n=min(int(pageSize), len(merged_data)))\n",
    "\n",
    "    # 将每个id对应的数据包装成json格式\n",
    "    \n",
    "    result_json = []\n",
    "    # for index, row in merged_data.iterrows():\n",
    "    for index, row in sample_data.iterrows():\n",
    "        data_dict = {\n",
    "            'artId': row['id'],\n",
    "            'total_rank': row['total_rank'],\n",
    "            'websiteUrl': row['url'],\n",
    "            'website_id': row['website_id'],\n",
    "            'request_url': row['request_url'],\n",
    "            'response_url': row['response_url'],\n",
    "            'artType': row['category1'],\n",
    "            # 'category2': row['category2'],\n",
    "            'artTitle': row['title'],\n",
    "            'abstract': row['abstract'],\n",
    "            'artContent': row['body'],\n",
    "            'artTime': row['pub_time'],\n",
    "            'cole_time': row['cole_time'],\n",
    "            'artImageUrl': row['images'],\n",
    "            'language_id': row['language_id'],\n",
    "            'md5': row['md5'],\n",
    "            'artCusId': 582,\n",
    "            # test\n",
    "            \"customer\": {\"cusId\": 582, \"cusName\": \"admin\",\n",
    "                         \"cusPass\": None,\n",
    "                         \"cusSpider\": \"\",\n",
    "                         \"cusAvatarUrl\": \"http://localhost:8080/img/Man.png\",\n",
    "                         \"cusStyle\": \"这个人很懒, 什么都没写\",\n",
    "                         \"cusGender\": 0,\n",
    "                         \"cusTime\": \"2024-03-14T21:53:09.000+0000\", \"cusLegal\": 0},\n",
    "            \"artFeature\": {\"afcId\": 710, \"afcArtId\": 20171864,\n",
    "                           \"afcLikeNum\": 0, \"afcDislikeNum\": 0,\n",
    "                           \"afcComNum\": 0, \"afcRepNum\": 0,\n",
    "                           \"afcReadNum\": 0,\n",
    "                           \"afcArtTime\": None},\n",
    "            \"cusArtBehavior\": None\n",
    "        }\n",
    "        result_json.append(data_dict)\n",
    "        # print(result_json)\n",
    "\n",
    "    return result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff43405-ad69-4ad2-b2c0-6b32ff3d37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "===================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c017b2cb-30f5-4d78-9306-704b93e1b937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [2024-04-03 11:20:48] \"GET /randomArt HTTP/1.1\" 404 363 0.001185\n",
      "[2024-04-03 11:20:55,799] ERROR in app: Exception on /random_art [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/default/lib/python3.8/site-packages/flask/app.py\", line 1463, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/opt/conda/envs/default/lib/python3.8/site-packages/flask/app.py\", line 872, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/opt/conda/envs/default/lib/python3.8/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"/opt/conda/envs/default/lib/python3.8/site-packages/flask/app.py\", line 870, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/opt/conda/envs/default/lib/python3.8/site-packages/flask/app.py\", line 855, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "  File \"/tmp/ipykernel_13562/1887435204.py\", line 83, in get_randomArt\n",
      "    result_json = get_randomArt_Impl(page,pageSize)\n",
      "  File \"/tmp/ipykernel_13562/2981686859.py\", line 192, in get_randomArt_Impl\n",
      "    sample_data = merged_data.sample(n=min(int(pageSize), len(merged_data)))\n",
      "TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [2024-04-03 11:20:55] \"GET /random_art HTTP/1.1\" 500 433 0.007596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [2024-04-03 11:21:31] \"GET /random_art?page=0&pageSize=6 HTTP/1.1\" 200 111337 0.004283\n",
      "KeyboardInterrupt\n",
      "2024-04-03T03:21:45Z\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# app.run(debug=True)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     server \u001b[38;5;241m=\u001b[39m pywsgi\u001b[38;5;241m.\u001b[39mWSGIServer((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m127.0.0.1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5399\u001b[39m), app)\n\u001b[0;32m---> 93\u001b[0m     \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/gevent/baseserver.py:400\u001b[0m, in \u001b[0;36mBaseServer.serve_forever\u001b[0;34m(self, stop_timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stop_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     Greenlet\u001b[38;5;241m.\u001b[39mspawn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop, timeout\u001b[38;5;241m=\u001b[39mstop_timeout)\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32msrc/gevent/event.py:163\u001b[0m, in \u001b[0;36mgevent._gevent_cevent.Event.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_abstract_linkable.py:521\u001b[0m, in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_abstract_linkable.py:487\u001b[0m, in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._wait_core\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_abstract_linkable.py:490\u001b[0m, in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._wait_core\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_abstract_linkable.py:442\u001b[0m, in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._AbstractLinkable__wait_to_be_notified\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_abstract_linkable.py:451\u001b[0m, in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._switch_to_hub\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_greenlet_primitives.py:61\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_greenlet_primitives.py:65\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_gevent_c_greenlet_primitives.pxd:35\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives._greenlet_switch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dev版 以上实际上在另一个文件\n",
    "# coding=utf8\n",
    "import pandas as pd\n",
    "from flask import *\n",
    "from flask_cors import CORS  # 导入CORS模块\n",
    "from gevent import pywsgi\n",
    "# from ProcessCode.survicesImpl import get_data_MIXed_Impl,get_data_ByType_Impl,get_Categorys_Impl,get_randomArt_Impl,get_ArtMain   正式版记得打开这个！！！！\n",
    "\n",
    "# 使用Flask创建算法接口\n",
    "app = Flask(__name__)\n",
    "# app.json.ensure_ascii = False  # 解决中文乱码问题  flask版本2.3.0以上使用\n",
    "app.config['JSON_AS_ASCII'] = False  # 解决中文乱码问题  flask版本 2.3.0以下使用\n",
    "\n",
    "CORS(app)  # 添加跨域支持\n",
    "\n",
    "# 获取“综合”类别的重要新闻\n",
    "@app.route('/get_data_mixed', methods=['GET'])\n",
    "def get_data_MIXed():\n",
    "\n",
    "    # 获取 URL 参数中的参数值\n",
    "    date_sel =  request.args.get('date_sel')\n",
    "    artType = request.args.get('artType')\n",
    "    page = request.args.get('page')\n",
    "    pageSize = request.args.get('pageSize')\n",
    "\n",
    "    result_json = get_data_MIXed_Impl(date_sel)\n",
    "\n",
    "    response = jsonify(result_json)\n",
    "    response.headers['Content-Type'] = 'application/json; charset=utf-8'\n",
    "    return response  # 将字节串解码为UTF-8字符串\n",
    "\n",
    "\n",
    "# 按类别获取类别的重要新闻（包括“综合”）\n",
    "@app.route('/get_data_by_type', methods=['GET'])\n",
    "def get_data_ByType():\n",
    "    # 获取 URL 参数中的参数值\n",
    "    date_sel =  request.args.get('date_sel') # 获取日期参数\n",
    "\n",
    "    artType = request.args.get('artType')\n",
    "    page = request.args.get('page')\n",
    "    pageSize = request.args.get('pageSize')\n",
    "    print(artType)\n",
    "    print(page)\n",
    "    print(pageSize)\n",
    "\n",
    "    # result_json = get_data_ByType_Impl(artType,page,pageSize)\n",
    "    result_json = get_data_ByType_Impl(date_sel,artType,page,pageSize)\n",
    "\n",
    "    response = jsonify(result_json)\n",
    "    # response = jsonify(test_json)\n",
    "    response.headers['Content-Type'] = 'application/json; charset=utf-8'\n",
    "    # return response.data.decode('utf-8')  # 将字节串解码为UTF-8字符串\n",
    "    return response  # 将字节串解码为UTF-8字符串\n",
    "\n",
    "@app.route('/type', methods=['GET'])\n",
    "def get_Categorys():\n",
    "    date_sel =  request.args.get('date_sel') # 获取日期参数\n",
    "        \n",
    "    category_list = get_Categorys_Impl(date_sel)\n",
    "\n",
    "    return jsonify(category_list)\n",
    "\n",
    "# 返回完整文章内容\n",
    "@app.route('/main', methods=['GET'])\n",
    "def get_ArtMain():\n",
    "    \n",
    "    date_sel =  request.args.get('date_sel') # 获取日期参数\n",
    "\n",
    "    # 获取artId参数的值\n",
    "    artId = request.args.get('artId')\n",
    "\n",
    "    result_dict = get_ArtMain(artId)\n",
    "    result_dict = get_ArtMain(date_sel,artId) # FIX\n",
    "\n",
    "    response = jsonify(result_dict)\n",
    "    response.headers['Content-Type'] = 'application/json; charset=utf-8'\n",
    "    return response  # 将字节串解码为UTF-8字符串\n",
    "\n",
    "    # 将筛选出的数据转换为字典形式\n",
    "    # data_dict = filtered_data.to_dict(orient='records')\n",
    "\n",
    "    # return jsonify(data_dict)\n",
    "\n",
    "# 右侧推荐新闻处 随机返回pageSize条新闻\n",
    "@app.route('/random_art', methods=['GET'])\n",
    "def get_randomArt():\n",
    "    \n",
    "    date_sel =  request.args.get('date_sel') # 获取日期参数\n",
    "\n",
    "    # 获取 URL 参数中的参数值\n",
    "    # artType = request.args.get('artType')\n",
    "    page = request.args.get('page')\n",
    "    pageSize = request.args.get('pageSize')\n",
    "    print(page)\n",
    "    print(pageSize)\n",
    "\n",
    "    # result_json = get_randomArt_Impl(page,pageSize)\n",
    "    result_json = get_randomArt_Impl(date_sel,page,pageSize) # FIX\n",
    "\n",
    "\n",
    "    response = jsonify(result_json)\n",
    "    response.headers['Content-Type'] = 'application/json; charset=utf-8'\n",
    "    return response  # 将字节串解码为UTF-8字符串\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # app.run(debug=True)\n",
    "    server = pywsgi.WSGIServer(('127.0.0.1', 5399), app)\n",
    "    server.serve_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b9d5c-0d0c-42f9-9a85-a7036b09306b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-default",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
