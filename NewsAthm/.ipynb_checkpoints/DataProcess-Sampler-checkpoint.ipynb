{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d005c9d-c5ab-45a7-b19f-e1f6c4045a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31978938  0.18256517  0.27844584 ... -0.5047224   0.52765423\n",
      "  -0.96845144]\n",
      " [ 0.26611075  0.15237056  0.28633723 ... -0.6395822   0.56409585\n",
      "  -1.0826756 ]\n",
      " [ 0.32402256  0.2667769   0.37864402 ... -0.6582319   0.50884926\n",
      "  -1.014228  ]\n",
      " ...\n",
      " [ 0.27147102  0.04560753  0.2685072  ... -0.43168148  0.6387473\n",
      "  -1.0556158 ]\n",
      " [ 0.36678466  0.17260373  0.38308302 ... -0.58664805  0.5102701\n",
      "  -1.0430468 ]\n",
      " [ 0.2669459   0.12637357  0.39293042 ... -0.508324    0.53113097\n",
      "  -1.1132029 ]]\n",
      "(10000, 768)\n",
      "[0 0 0 ... 0 4 4]\n",
      "(10000,)\n",
      "Counter({0: 7589, 2: 923, 1: 709, 6: 217, 5: 199, 3: 194, 4: 169})\n",
      "[7589  709  923  194  169  199  217]\n",
      "(11254, 768)\n",
      "(11254,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/conda/envs/default/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/conda/envs/default/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3533, 768)\n",
      "(3533,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 500, 1: 500, 2: 500, 3: 477, 4: 488, 5: 529, 6: 539})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "df = pd.read_csv('./deduplicated_mangoNews_Nums3000p_CategoryMerge_new_10000.csv')  # 假设你有一个CSV文件包含数据\n",
    "# 假设你的数据集有 'body' 列和 'category1' 列\n",
    "\n",
    "# 初始化 BERT tokenizer 和模型\n",
    "Bert_path = './uncased_L-12_H-768_A-12'\n",
    "tokenizer = BertTokenizer.from_pretrained(Bert_path)\n",
    "model = BertModel.from_pretrained(Bert_path)\n",
    "\n",
    "# 对文本进行编码\n",
    "max_length = 384  # 设定一个合适的最大长度，可以根据你的数据进行调整\n",
    "encoded_texts = []\n",
    "for text in df['body']:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=max_length)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    encoded_text = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    encoded_texts.append(encoded_text)\n",
    "\n",
    "\n",
    "X = np.vstack(encoded_texts)\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "# 对类别标签进行编码\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['category1'])\n",
    "print(y)\n",
    "print(y.shape)\n",
    "print(Counter(y))\n",
    "\n",
    "# 数据平衡处理\n",
    "target_count = 500\n",
    "class_counts = np.bincount(y)\n",
    "print(class_counts)\n",
    "\n",
    "adasyn = ADASYN(sampling_strategy={cls: target_count for cls, count in enumerate(class_counts) if count < target_count})\n",
    "cluster_centroids = ClusterCentroids(sampling_strategy={cls: target_count for cls, count in enumerate(class_counts) if count > target_count})\n",
    "\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X, y)\n",
    "print(X_resampled.shape)\n",
    "print(y_resampled.shape)\n",
    "Counter(y_resampled)\n",
    "X_resampled, y_resampled = cluster_centroids.fit_resample(X_resampled, y_resampled)\n",
    "print(X_resampled.shape)\n",
    "print(y_resampled.shape)\n",
    "Counter(y_resampled)\n",
    "\n",
    "# 现在可以继续使用 X_resampled 和 y_resampled 进行模型训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f38606-ad41-4129-b75e-e311b965a8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n",
      "(1000,)\n",
      "Original dataset shape Counter({1: 900, 0: 100})\n",
      "(1804, 20)\n",
      "(1804,)\n",
      "Resampled dataset shape Counter({0: 904, 1: 900})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import ADASYN\n",
    "X, y = make_classification(n_classes=2, class_sep=2,\n",
    "                           weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "                           n_features=20, n_clusters_per_class=1, n_samples=1000,\n",
    "                           random_state=10)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "ada = ADASYN(random_state=42)\n",
    "X_res, y_res = ada.fit_resample(X, y)\n",
    "print(X_res.shape)\n",
    "print(y_res.shape)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac62f1cf-79ca-45f8-bb26-16ddee0e09c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_6880/335907251.py:9: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv')  # 假设你有一个CSV文件包含数据\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "                                                       body   category1\n",
      "1537      ডরিন হোটেলে স্ট্রিট ফুড মার্কেটভোজনরসিকদের জন্...  লাইফস্টাইল\n",
      "1538      বাজারে এল অ্যাপলের নতুন ম্যাকবুক প্রোর দুটি মড...  লাইফস্টাইল\n",
      "1539      উপহার সব সময় যে দামিই হতে হবে, এমন কোনো দিব্যি...  লাইফস্টাইল\n",
      "1540      ফ্যাশনের আলাপে ঘুরেফিরেই আসে ডাচেস অব কেমব্রিজ...  লাইফস্টাইল\n",
      "1541      ২৮ মে শেষ হয়ে যাবে ৭৫তম কান চলচ্চিত্র উৎসব। চল...  লাইফস্টাইল\n",
      "...                                                     ...         ...\n",
      "21533495                                                NaN    অন্যান্য\n",
      "9132841                                                 NaN    অন্যান্য\n",
      "6240778                                                 NaN    অন্যান্য\n",
      "21014746                                                NaN    অন্যান্য\n",
      "14414911                                                NaN    অন্যান্য\n",
      "\n",
      "[35276919 rows x 2 columns]\n",
      "                                                       body   category1\n",
      "1537      ডরিন হোটেলে স্ট্রিট ফুড মার্কেটভোজনরসিকদের জন্...  লাইফস্টাইল\n",
      "1538      বাজারে এল অ্যাপলের নতুন ম্যাকবুক প্রোর দুটি মড...  লাইফস্টাইল\n",
      "1539      উপহার সব সময় যে দামিই হতে হবে, এমন কোনো দিব্যি...  লাইফস্টাইল\n",
      "1540      ফ্যাশনের আলাপে ঘুরেফিরেই আসে ডাচেস অব কেমব্রিজ...  লাইফস্টাইল\n",
      "1541      ২৮ মে শেষ হয়ে যাবে ৭৫তম কান চলচ্চিত্র উৎসব। চল...  লাইফস্টাইল\n",
      "...                                                     ...         ...\n",
      "16826850                                                NaN       জাতীয়\n",
      "18894327                                                NaN       জাতীয়\n",
      "9954202                                                 NaN       জাতীয়\n",
      "9954510                                                 NaN       জাতীয়\n",
      "18110074                                                NaN       জাতীয়\n",
      "\n",
      "[33259386 rows x 2 columns]\n",
      "                                                       body    category1\n",
      "1537      ডরিন হোটেলে স্ট্রিট ফুড মার্কেটভোজনরসিকদের জন্...   লাইফস্টাইল\n",
      "1538      বাজারে এল অ্যাপলের নতুন ম্যাকবুক প্রোর দুটি মড...   লাইফস্টাইল\n",
      "1539      উপহার সব সময় যে দামিই হতে হবে, এমন কোনো দিব্যি...   লাইফস্টাইল\n",
      "1540      ফ্যাশনের আলাপে ঘুরেফিরেই আসে ডাচেস অব কেমব্রিজ...   লাইফস্টাইল\n",
      "1541      ২৮ মে শেষ হয়ে যাবে ৭৫তম কান চলচ্চিত্র উৎসব। চল...   লাইফস্টাইল\n",
      "...                                                     ...          ...\n",
      "499962    ইউক্রেনে বেশ কয়েকজন রুশ সেনা রাসায়নিক বিষক্রিয়...  আন্তর্জাতিক\n",
      "485752    কার্গো বিমানে মালামাল উঠাচ্ছিলেন এক কর্মী। নিজ...  আন্তর্জাতিক\n",
      "22073984                                                NaN  আন্তর্জাতিক\n",
      "8095964                                                 NaN  আন্তর্জাতিক\n",
      "14130497                                                NaN  আন্তর্জাতিক\n",
      "\n",
      "[32318190 rows x 2 columns]\n",
      "                                                       body   category1\n",
      "1537      ডরিন হোটেলে স্ট্রিট ফুড মার্কেটভোজনরসিকদের জন্...  লাইফস্টাইল\n",
      "1538      বাজারে এল অ্যাপলের নতুন ম্যাকবুক প্রোর দুটি মড...  লাইফস্টাইল\n",
      "1539      উপহার সব সময় যে দামিই হতে হবে, এমন কোনো দিব্যি...  লাইফস্টাইল\n",
      "1540      ফ্যাশনের আলাপে ঘুরেফিরেই আসে ডাচেস অব কেমব্রিজ...  লাইফস্টাইল\n",
      "1541      ২৮ মে শেষ হয়ে যাবে ৭৫তম কান চলচ্চিত্র উৎসব। চল...  লাইফস্টাইল\n",
      "...                                                     ...         ...\n",
      "17594015                                                NaN    খেলাধুলা\n",
      "17619872                                                NaN    খেলাধুলা\n",
      "20207420                                                NaN    খেলাধুলা\n",
      "19445941                                                NaN    খেলাধুলা\n",
      "30702879                                                NaN    খেলাধুলা\n",
      "\n",
      "[30008283 rows x 2 columns]\n",
      "                                                       body   category1\n",
      "1537      ডরিন হোটেলে স্ট্রিট ফুড মার্কেটভোজনরসিকদের জন্...  লাইফস্টাইল\n",
      "1538      বাজারে এল অ্যাপলের নতুন ম্যাকবুক প্রোর দুটি মড...  লাইফস্টাইল\n",
      "1539      উপহার সব সময় যে দামিই হতে হবে, এমন কোনো দিব্যি...  লাইফস্টাইল\n",
      "1540      ফ্যাশনের আলাপে ঘুরেফিরেই আসে ডাচেস অব কেমব্রিজ...  লাইফস্টাইল\n",
      "1541      ২৮ মে শেষ হয়ে যাবে ৭৫তম কান চলচ্চিত্র উৎসব। চল...  লাইফস্টাইল\n",
      "...                                                     ...         ...\n",
      "10999270                                                NaN     রাজনীতি\n",
      "24694857                                                NaN     রাজনীতি\n",
      "10979412                                                NaN     রাজনীতি\n",
      "10979630                                                NaN     রাজনীতি\n",
      "10726762                                                NaN     রাজনীতি\n",
      "\n",
      "[29523692 rows x 2 columns]\n",
      "                                                       body   category1\n",
      "1537      ডরিন হোটেলে স্ট্রিট ফুড মার্কেটভোজনরসিকদের জন্...  লাইফস্টাইল\n",
      "1538      বাজারে এল অ্যাপলের নতুন ম্যাকবুক প্রোর দুটি মড...  লাইফস্টাইল\n",
      "1539      উপহার সব সময় যে দামিই হতে হবে, এমন কোনো দিব্যি...  লাইফস্টাইল\n",
      "1540      ফ্যাশনের আলাপে ঘুরেফিরেই আসে ডাচেস অব কেমব্রিজ...  লাইফস্টাইল\n",
      "1541      ২৮ মে শেষ হয়ে যাবে ৭৫তম কান চলচ্চিত্র উৎসব। চল...  লাইফস্টাইল\n",
      "...                                                     ...         ...\n",
      "27049723                                                NaN      বিনোদন\n",
      "29374395                                                NaN      বিনোদন\n",
      "27033347                                                NaN      বিনোদন\n",
      "29376474                                                NaN      বিনোদন\n",
      "28582633                                                NaN      বিনোদন\n",
      "\n",
      "[29172431 rows x 2 columns]\n",
      "                                                       body   category1\n",
      "1537      ডরিন হোটেলে স্ট্রিট ফুড মার্কেটভোজনরসিকদের জন্...  লাইফস্টাইল\n",
      "1538      বাজারে এল অ্যাপলের নতুন ম্যাকবুক প্রোর দুটি মড...  লাইফস্টাইল\n",
      "1539      উপহার সব সময় যে দামিই হতে হবে, এমন কোনো দিব্যি...  লাইফস্টাইল\n",
      "1540      ফ্যাশনের আলাপে ঘুরেফিরেই আসে ডাচেস অব কেমব্রিজ...  লাইফস্টাইল\n",
      "1541      ২৮ মে শেষ হয়ে যাবে ৭৫তম কান চলচ্চিত্র উৎসব। চল...  লাইফস্টাইল\n",
      "...                                                     ...         ...\n",
      "36477042                                                NaN    অর্থনীতি\n",
      "36477405                                                NaN    অর্থনীতি\n",
      "845421    ঈদের বাকি দুই দিন। ইতিমধ্যে ফাঁকা হয়ে গেছে কোট...    অর্থনীতি\n",
      "12555930                                                NaN    অর্থনীতি\n",
      "23914566                                                NaN    অর্থনীতি\n",
      "\n",
      "[28631627 rows x 2 columns]\n",
      "                                                       body   category1\n",
      "1537      ডরিন হোটেলে স্ট্রিট ফুড মার্কেটভোজনরসিকদের জন্...  লাইফস্টাইল\n",
      "1538      বাজারে এল অ্যাপলের নতুন ম্যাকবুক প্রোর দুটি মড...  লাইফস্টাইল\n",
      "1539      উপহার সব সময় যে দামিই হতে হবে, এমন কোনো দিব্যি...  লাইফস্টাইল\n",
      "1540      ফ্যাশনের আলাপে ঘুরেফিরেই আসে ডাচেস অব কেমব্রিজ...  লাইফস্টাইল\n",
      "1541      ২৮ মে শেষ হয়ে যাবে ৭৫তম কান চলচ্চিত্র উৎসব। চল...  লাইফস্টাইল\n",
      "...                                                     ...         ...\n",
      "22312592                                                NaN         আইন\n",
      "7324728                                                 NaN         আইন\n",
      "22291173                                                NaN         আইন\n",
      "934614    ডাণ্ডাবেড়ি পরিয়ে আসামিকে হাইকোর্টে হাজির করানো...         আইন\n",
      "22340103                                                NaN         আইন\n",
      "\n",
      "[28364659 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'augly.text.augmenters' has no attribute 'replace_similar_unicode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m sampled_indices:\n\u001b[1;32m     46\u001b[0m     original_text \u001b[38;5;241m=\u001b[39m df_category\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 47\u001b[0m     augmented_text \u001b[38;5;241m=\u001b[39m \u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_similar_unicode\u001b[49m(original_text)\n\u001b[1;32m     48\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m: augmented_text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory1\u001b[39m\u001b[38;5;124m'\u001b[39m: category}, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'augly.text.augmenters' has no attribute 'replace_similar_unicode'"
     ]
    }
   ],
   "source": [
    "# !pip install augly\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "# from augly.text import augmentation\n",
    "from augly.text import augmenters as augmentation\n",
    "import random\n",
    "\n",
    "# 加载数据集\n",
    "df = pd.read_csv('./deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv')  # 假设你有一个CSV文件包含数据\n",
    "# 假设你的数据集有 'body' 列和 'category1' 列\n",
    "print(\"!\")\n",
    "# 提取 body 列和 category1 列\n",
    "df = df[['body', 'category1']]\n",
    "\n",
    "# 定义类别对应的语料数目\n",
    "class_counts = {\n",
    "    'অন্যান্য': 361535,\n",
    "    'জাতীয়': 343724,\n",
    "    'আন্তর্জাতিক': 119419,\n",
    "    'খেলাধুলা': 111943,\n",
    "    'রাজনীতি': 55988,\n",
    "    'বিনোদন': 53591,\n",
    "    'অর্থনীতি': 46574,\n",
    "    'আইন': 34876,\n",
    "    'আর্কাইভ': 28279,\n",
    "    'শিক্ষা': 22374,\n",
    "    'বিজ্ঞান': 12335,\n",
    "    'লাইফস্টাইল': 12095\n",
    "}\n",
    "\n",
    "# 数据平衡处理\n",
    "target_count = 30000\n",
    "for category, count in class_counts.items():\n",
    "    if count > target_count:\n",
    "        # 随机欠采样，使语料数量约等于30000\n",
    "        df_category = df[df['category1'] == category]\n",
    "        df_downsampled = resample(df_category, replace=False, n_samples=target_count, random_state=42)\n",
    "        df = pd.concat([df[df['category1'] != category], df_downsampled])\n",
    "        print(df)\n",
    "    elif count < target_count:\n",
    "        # 使用AugLy进行数据增强，使语料数量约等于30000\n",
    "        df_category = df[df['category1'] == category]\n",
    "        num_augmentations = target_count - count\n",
    "        sampled_indices = random.sample(range(len(df_category)), num_augmentations)\n",
    "        for idx in sampled_indices:\n",
    "            original_text = df_category.iloc[idx]['body']\n",
    "            augmented_text = augmentation.replace_similar_unicode(original_text)\n",
    "            df = df.append({'body': augmented_text, 'category1': category}, ignore_index=True)\n",
    "        print(df)\n",
    "\n",
    "# 确保各个类别对应的语料数量大致为30000\n",
    "class_counts_final = df['category1'].value_counts()\n",
    "print(class_counts_final)\n",
    "\n",
    "# 现在可以继续使用处理后的数据进行后续任务\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de22816c-c557-4658-adcb-6ef5eb15135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "欠采样后的类别计数:\n",
      "খেলাধুলা      6431\n",
      "রাজনীতি       6431\n",
      "বিনোদন        6431\n",
      "অর্থনীতি      6431\n",
      "আইন           6431\n",
      "শিক্ষা        6431\n",
      "বিজ্ঞান       6431\n",
      "লাইফস্টাইল    6431\n",
      "অন্যান্য      6431\n",
      "Name: category1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 暂时使用这个！！使用随机欠采样对数据集进行数据平衡，最终数据集为12095*12=145140条 1.2g，改进方向：欠采样（culster）+过采样（adasyn，augly增强）\n",
    "# update:3.7\n",
    "# update：3.8\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 读取CSV文件\n",
    "# df = pd.read_csv('./deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv', low_memory=False,lineterminator=\"\\n\")\n",
    "# df = pd.read_csv('./datasets_FIX/FIX_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv', low_memory=False,lineterminator=\"\\n\")\n",
    "# df = pd.read_csv('./datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv', low_memory=False,lineterminator=\"\\n\")\n",
    "df = pd.read_csv('./datasets_FIX3/FIX3_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv', low_memory=False,lineterminator=\"\\n\")\n",
    "\n",
    "# datasets_FIX/FIX_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv\n",
    "\n",
    "# 统计各类别对应的语料数\n",
    "category_counts = df['category1'].value_counts().to_dict()\n",
    "\n",
    "# 找出最小的语料数\n",
    "min_corpus_count = min(category_counts.values())\n",
    "\n",
    "# 对每个类别进行欠采样\n",
    "undersampled_dfs = []\n",
    "for category, count in category_counts.items():\n",
    "    # 获取当前类别的所有索引\n",
    "    indices = df[df['category1'] == category].index\n",
    "    # 如果当前类别的语料数大于最小语料数，则进行欠采样\n",
    "    if count > min_corpus_count:\n",
    "        undersampled_indices = resample(indices, replace=False, n_samples=min_corpus_count, random_state=42)\n",
    "        undersampled_df = df.loc[undersampled_indices]\n",
    "        undersampled_dfs.append(undersampled_df)\n",
    "    else:\n",
    "        undersampled_dfs.append(df.loc[indices])\n",
    "\n",
    "# 将欠采样后的DataFrame合并为一个新的DataFrame\n",
    "undersampled_df = pd.concat(undersampled_dfs)\n",
    "\n",
    "# 输出欠采样后的类别计数\n",
    "print(\"\\n欠采样后的类别计数:\")\n",
    "print(undersampled_df['category1'].value_counts())\n",
    "\n",
    "undersampled_df.head()\n",
    "\n",
    "# 保存处理后的结果到新的CSV文件\n",
    "# undersampled_df.to_csv('./datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled.csv', index=False)\n",
    "undersampled_df.to_csv('./datasets_FIX3/FIX3_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "804d417b-1d14-4348-92ba-7fac6006d199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "采样后的数据信息:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57879 entries, 89218 to 274415\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            57879 non-null  int64 \n",
      " 1   website_id    57879 non-null  int64 \n",
      " 2   request_url   57879 non-null  object\n",
      " 3   response_url  57879 non-null  object\n",
      " 4   category1     57879 non-null  object\n",
      " 5   category2     933 non-null    object\n",
      " 6   title         57879 non-null  object\n",
      " 7   abstract      57860 non-null  object\n",
      " 8   body          57871 non-null  object\n",
      " 9   pub_time      57879 non-null  object\n",
      " 10  cole_time     57879 non-null  object\n",
      " 11  images        57879 non-null  object\n",
      " 12  language_id   57879 non-null  int64 \n",
      "          57879 non-null  object\n",
      "dtypes: int64(3), object(11)\n",
      "memory usage: 6.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 对数据平衡前数据集进行随机抽取145140条用于bert训练后与数据平衡后数据效果进行对比\n",
    "# update：3.8\n",
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "# df = pd.read_csv('./deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv', low_memory=False,lineterminator=\"\\n\")\n",
    "# df = pd.read_csv('./datasets_FIX/FIX_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv', low_memory=False,lineterminator=\"\\n\")\n",
    "# df = pd.read_csv('./datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv', low_memory=False,lineterminator=\"\\n\")\n",
    "df = pd.read_csv('./datasets_FIX3/FIX3_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv', low_memory=False,lineterminator=\"\\n\")\n",
    "\n",
    "# 随机采样145140条数据\n",
    "sampled_df = df.sample(n=57879, random_state=42)\n",
    "\n",
    "# 保存采样结果到新的CSV文件\n",
    "# sampled_df.to_csv('./datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_randsample110502.csv', index=False)\n",
    "sampled_df.to_csv('./datasets_FIX3/FIX3_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_randsample57879.csv', index=False)\n",
    "\n",
    "# 输出采样后的数据信息\n",
    "print(\"采样后的数据信息:\")\n",
    "print(sampled_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add25d04-288c-4d16-b5e3-e23d1047d1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Counts:\n",
      "Index(['খেলাধুলা', 'আইন', 'রাজনীতি', 'অর্থনীতি', 'লাইফস্টাইল', 'শিক্ষা',\n",
      "       'অন্যান্য', 'বিজ্ঞান', 'বিনোদন'],\n",
      "      dtype='object')\n",
      "Category Counts1:\n",
      "খেলাধুলা      105\n",
      "লাইফস্টাইল    102\n",
      "অর্থনীতি      101\n",
      "আইন            97\n",
      "রাজনীতি        97\n",
      "শিক্ষা         94\n",
      "অন্যান্য       91\n",
      "বিজ্ঞান        83\n",
      "বিনোদন         80\n",
      "Name: category1, dtype: int64\n",
      "===================================================\n",
      "Category Counts2:\n",
      "আইন           22\n",
      "রাজনীতি       21\n",
      "বিজ্ঞান       19\n",
      "অর্থনীতি      17\n",
      "খেলাধুলা      16\n",
      "বিনোদন        15\n",
      "শিক্ষা        14\n",
      "অন্যান্য      14\n",
      "লাইফস্টাইল    12\n",
      "Name: category1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "# 划分训练集测试集用于ALbert+seq2seq_attention\n",
    "# 读取CSV文件\n",
    "# file_path = './datasets/mangoNews_Example.csv'  # 测试版数据集（规模小5m）\n",
    "# file_path = './datasets/mangoNews.csv'          # 完整版数据集（13g） 需要分块读\n",
    "# file_path = './datasets/mangoNews_Example_100000.csv'          # 100000行数据集（2.2g）\n",
    "# file_path = './datasets/mangoNews_Example_10000.csv'          # 10000行数据集（190m)\n",
    "# file_path = './datasets/deduplicated_mangoNews_Nums3000p_CategoryMerge.csv'          # 去重后保留类别对应语料数在3000+并合并同义类别的数据集（9.9g) 需要分块读\n",
    "# file_path = './datasets/deduplicated_mangoNews_Nums3000p_CategoryMerge_100000_1.csv'          # 去重后保留类别对应语料数在3000+并合并同义类别的数据集（576m) \n",
    "# file_path = './datasets/deduplicated_mangoNews_Nums3000p_CategoryMerge_990000.csv'          # 去重后保留类别对应语料数在3000+并合并同义类别的数据集（8.1g) \n",
    "# file_path = './datasets/deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled.csv'          # 去重后保留类别对应语料数在3000+并合并同义类别(新）并随机欠采样数据平衡的数据集（12095*12条 1.2g) \n",
    "# file_path = './datasets/deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled_Example.csv'          # 去重后保留类别对应语料数在3000+并合并同义类别(新）并随机欠采样数据平衡的数据集（12095*12条 1.2g) \n",
    "\n",
    "# file_path = './datasets_FIX/FIX_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled.csv'\n",
    "# file_path = './datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled.csv'\n",
    "file_path = './datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled_Example.csv'\n",
    "\n",
    "\n",
    "data = pd.read_csv(file_path,low_memory=False,lineterminator=\"\\n\")\n",
    "\n",
    "# Select relevant columns\n",
    "data = data[['body', 'category1']]\n",
    "\n",
    "category_counts = data['category1'].value_counts()\n",
    "\n",
    "# 设置显示选项，完整输出结果\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(\"Category Counts:\")\n",
    "print(category_counts.index)\n",
    "# 恢复默认显示选项\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_data, test_data = train_test_split(data, test_size=0.15, random_state=42) ## 2.20 test_size:0.2->0.3\n",
    "\n",
    "# 保存训练集到 train.csv\n",
    "train_data.to_csv('./datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled_train_Example.csv', index=False)\n",
    "# train_data.to_csv('./datasets/mangoNews_Example_train.csv', index=False)\n",
    "\n",
    "# 保存测试集到 test.csv\n",
    "test_data.to_csv('./datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled_test_Example.csv', index=False)\n",
    "# test_data.to_csv('./datasets/mangoNews_Example_test.csv', index=False)\n",
    "\n",
    "\n",
    "# 统计 'category1' 列中每种类别的个数\n",
    "category_counts1 = train_data['category1'].value_counts()\n",
    "\n",
    "# 设置显示选项，完整输出结果\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(\"Category Counts1:\")\n",
    "print(category_counts1)\n",
    "# 恢复默认显示选项\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "category_counts2 = test_data['category1'].value_counts()\n",
    "print(\"===================================================\")\n",
    "# 设置显示选项，完整输出结果\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(\"Category Counts2:\")\n",
    "print(category_counts2)\n",
    "# 恢复默认显示选项\n",
    "pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba81f8c0-f58f-4eda-ace0-99d7b5d3f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取原始数据集\n",
    "# file_path = './datasets/deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled.csv'\n",
    "file_path = './datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled.csv'\n",
    "\n",
    "data = pd.read_csv(file_path,low_memory=False,lineterminator=\"\\n\")\n",
    "\n",
    "# 随机抽样1000条数据\n",
    "sampled_data = data.sample(n=1000, random_state=42)\n",
    "\n",
    "# 将抽样后的数据保存到新的CSV文件中\n",
    "sampled_data.to_csv('./datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled_Example.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b785eb-1352-4d93-a8be-05a018b8369f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
