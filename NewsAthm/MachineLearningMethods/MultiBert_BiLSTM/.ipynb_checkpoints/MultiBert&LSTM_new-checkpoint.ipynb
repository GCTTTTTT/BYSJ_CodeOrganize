{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea37124-b1a2-4009-84da-469573a54955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7deb77-4667-48a2-a7d9-899b55fd3954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 设置随机种子\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 加载数据\n",
    "file_path = '../datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled_Example.csv'\n",
    "# file_path = '../datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled.csv'\n",
    "\n",
    "data = pd.read_csv(file_path,low_memory=False,lineterminator=\"\\n\")\n",
    "\n",
    "# 加载BERT tokenizer和模型\n",
    "model_name = '../bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "bert_model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# 将模型移动到GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2401d681-5171-43dd-a799-d66bb2a3db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集类\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 将孟加拉语类别转换为数字标签\n",
    "label_map = {label: i for i, label in enumerate(data['category1'].unique())}\n",
    "labels = data['category1'].map(label_map).tolist()\n",
    "\n",
    "# 定义LSTM分类器\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size, num_classes, num_layers=1, bidirectional=True, dropout=0.5):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(bert_model.config.hidden_size, hidden_size, num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * (2 if bidirectional else 1), num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        lstm_output, _ = self.lstm(last_hidden_state)\n",
    "        lstm_output = self.dropout(lstm_output[:, -1, :])\n",
    "        logits = self.fc(lstm_output)\n",
    "        return logits\n",
    "\n",
    "# 定义训练和评估函数\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(data_loader, desc='Training', leave=False)\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        print(logits)\n",
    "        print(labels)\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate(model, data_loader, device, label_map):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            batch_predictions = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(batch_predictions.tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "\n",
    "    label_map_inv = {v: k for k, v in label_map.items()}\n",
    "    predictions = [label_map_inv[i] for i in predictions]\n",
    "    true_labels = [label_map_inv[i] for i in true_labels]\n",
    "\n",
    "    report = classification_report(true_labels, predictions, digits=4)\n",
    "    return report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d140bde-ec6a-4073-976d-debadd233b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Train Loss: 1.2073\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     0.9286    0.7222    0.8125        18\n",
      "    অর্থনীতি     0.9600    0.8276    0.8889        29\n",
      "         আইন     0.8182    1.0000    0.9000        27\n",
      "    খেলাধুলা     0.9583    1.0000    0.9787        23\n",
      "     বিজ্ঞান     0.9583    0.9583    0.9583        24\n",
      "      বিনোদন     0.9545    1.0000    0.9767        21\n",
      "     রাজনীতি     1.0000    0.9200    0.9583        25\n",
      "  লাইফস্টাইল     0.9375    0.8824    0.9091        17\n",
      "      শিক্ষা     0.7368    0.8750    0.8000        16\n",
      "\n",
      "    accuracy                         0.9150       200\n",
      "   macro avg     0.9169    0.9095    0.9092       200\n",
      "weighted avg     0.9223    0.9150    0.9147       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "Train Loss: 0.6466\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.7222    0.8387        18\n",
      "    অর্থনীতি     0.9630    0.8966    0.9286        29\n",
      "         আইন     0.8667    0.9630    0.9123        27\n",
      "    খেলাধুলা     0.9583    1.0000    0.9787        23\n",
      "     বিজ্ঞান     0.9200    0.9583    0.9388        24\n",
      "      বিনোদন     0.9545    1.0000    0.9767        21\n",
      "     রাজনীতি     0.9615    1.0000    0.9804        25\n",
      "  লাইফস্টাইল     0.9412    0.9412    0.9412        17\n",
      "      শিক্ষা     0.8750    0.8750    0.8750        16\n",
      "\n",
      "    accuracy                         0.9350       200\n",
      "   macro avg     0.9378    0.9285    0.9300       200\n",
      "weighted avg     0.9377    0.9350    0.9336       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Best Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.7222    0.8387        18\n",
      "    অর্থনীতি     0.9630    0.8966    0.9286        29\n",
      "         আইন     0.8667    0.9630    0.9123        27\n",
      "    খেলাধুলা     0.9583    1.0000    0.9787        23\n",
      "     বিজ্ঞান     0.9200    0.9583    0.9388        24\n",
      "      বিনোদন     0.9545    1.0000    0.9767        21\n",
      "     রাজনীতি     0.9615    1.0000    0.9804        25\n",
      "  লাইফস্টাইল     0.9412    0.9412    0.9412        17\n",
      "      শিক্ষা     0.8750    0.8750    0.8750        16\n",
      "\n",
      "    accuracy                         0.9350       200\n",
      "   macro avg     0.9378    0.9285    0.9300       200\n",
      "weighted avg     0.9377    0.9350    0.9336       200\n",
      "\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Train Loss: 1.2319\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.8696    0.9302        23\n",
      "    অর্থনীতি     1.0000    0.9000    0.9474        20\n",
      "         আইন     1.0000    1.0000    1.0000        22\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        25\n",
      "     বিজ্ঞান     0.9286    0.9286    0.9286        14\n",
      "      বিনোদন     1.0000    1.0000    1.0000        22\n",
      "     রাজনীতি     0.9200    1.0000    0.9583        23\n",
      "  লাইফস্টাইল     0.8438    0.9643    0.9000        28\n",
      "      শিক্ষা     1.0000    0.9565    0.9778        23\n",
      "\n",
      "    accuracy                         0.9600       200\n",
      "   macro avg     0.9658    0.9577    0.9603       200\n",
      "weighted avg     0.9639    0.9600    0.9604       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "Train Loss: 0.6458\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.9130    0.9545        23\n",
      "    অর্থনীতি     1.0000    0.8500    0.9189        20\n",
      "         আইন     0.9130    0.9545    0.9333        22\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        25\n",
      "     বিজ্ঞান     0.8235    1.0000    0.9032        14\n",
      "      বিনোদন     0.9565    1.0000    0.9778        22\n",
      "     রাজনীতি     0.9565    0.9565    0.9565        23\n",
      "  লাইফস্টাইল     0.9259    0.8929    0.9091        28\n",
      "      শিক্ষা     0.9167    0.9565    0.9362        23\n",
      "\n",
      "    accuracy                         0.9450       200\n",
      "   macro avg     0.9436    0.9471    0.9433       200\n",
      "weighted avg     0.9483    0.9450    0.9450       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Best Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.8696    0.9302        23\n",
      "    অর্থনীতি     1.0000    0.9000    0.9474        20\n",
      "         আইন     1.0000    1.0000    1.0000        22\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        25\n",
      "     বিজ্ঞান     0.9286    0.9286    0.9286        14\n",
      "      বিনোদন     1.0000    1.0000    1.0000        22\n",
      "     রাজনীতি     0.9200    1.0000    0.9583        23\n",
      "  লাইফস্টাইল     0.8438    0.9643    0.9000        28\n",
      "      শিক্ষা     1.0000    0.9565    0.9778        23\n",
      "\n",
      "    accuracy                         0.9600       200\n",
      "   macro avg     0.9658    0.9577    0.9603       200\n",
      "weighted avg     0.9639    0.9600    0.9604       200\n",
      "\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Train Loss: 1.1606\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     0.9500    0.7917    0.8636        24\n",
      "    অর্থনীতি     0.9444    0.8500    0.8947        20\n",
      "         আইন     0.9565    1.0000    0.9778        22\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        19\n",
      "     বিজ্ঞান     0.8571    0.9000    0.8780        20\n",
      "      বিনোদন     1.0000    0.9500    0.9744        20\n",
      "     রাজনীতি     0.8800    1.0000    0.9362        22\n",
      "  লাইফস্টাইল     0.9130    1.0000    0.9545        21\n",
      "      শিক্ষা     0.9375    0.9375    0.9375        32\n",
      "\n",
      "    accuracy                         0.9350       200\n",
      "   macro avg     0.9376    0.9366    0.9352       200\n",
      "weighted avg     0.9370    0.9350    0.9341       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "Train Loss: 0.6137\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     0.9500    0.7917    0.8636        24\n",
      "    অর্থনীতি     0.9048    0.9500    0.9268        20\n",
      "         আইন     0.9565    1.0000    0.9778        22\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        19\n",
      "     বিজ্ঞান     0.9000    0.9000    0.9000        20\n",
      "      বিনোদন     1.0000    0.9500    0.9744        20\n",
      "     রাজনীতি     0.8800    1.0000    0.9362        22\n",
      "  লাইফস্টাইল     0.9524    0.9524    0.9524        21\n",
      "      শিক্ষা     0.9375    0.9375    0.9375        32\n",
      "\n",
      "    accuracy                         0.9400       200\n",
      "   macro avg     0.9424    0.9424    0.9410       200\n",
      "weighted avg     0.9415    0.9400    0.9393       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     0.9500    0.7917    0.8636        24\n",
      "    অর্থনীতি     0.9048    0.9500    0.9268        20\n",
      "         আইন     0.9565    1.0000    0.9778        22\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        19\n",
      "     বিজ্ঞান     0.9000    0.9000    0.9000        20\n",
      "      বিনোদন     1.0000    0.9500    0.9744        20\n",
      "     রাজনীতি     0.8800    1.0000    0.9362        22\n",
      "  লাইফস্টাইল     0.9524    0.9524    0.9524        21\n",
      "      শিক্ষা     0.9375    0.9375    0.9375        32\n",
      "\n",
      "    accuracy                         0.9400       200\n",
      "   macro avg     0.9424    0.9424    0.9410       200\n",
      "weighted avg     0.9415    0.9400    0.9393       200\n",
      "\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Train Loss: 1.1413\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.7391    0.8500        23\n",
      "    অর্থনীতি     1.0000    1.0000    1.0000        25\n",
      "         আইন     0.9310    1.0000    0.9643        27\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        32\n",
      "     বিজ্ঞান     0.9130    1.0000    0.9545        21\n",
      "      বিনোদন     1.0000    1.0000    1.0000         7\n",
      "     রাজনীতি     0.9643    0.9643    0.9643        28\n",
      "  লাইফস্টাইল     0.9565    1.0000    0.9778        22\n",
      "      শিক্ষা     0.8750    0.9333    0.9032        15\n",
      "\n",
      "    accuracy                         0.9600       200\n",
      "   macro avg     0.9600    0.9596    0.9571       200\n",
      "weighted avg     0.9624    0.9600    0.9585       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "Train Loss: 0.5602\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.6957    0.8205        23\n",
      "    অর্থনীতি     0.9615    1.0000    0.9804        25\n",
      "         আইন     0.9286    0.9630    0.9455        27\n",
      "    খেলাধুলা     0.9697    1.0000    0.9846        32\n",
      "     বিজ্ঞান     0.9524    0.9524    0.9524        21\n",
      "      বিনোদন     1.0000    1.0000    1.0000         7\n",
      "     রাজনীতি     0.9310    0.9643    0.9474        28\n",
      "  লাইফস্টাইল     0.9167    1.0000    0.9565        22\n",
      "      শিক্ষা     0.8750    0.9333    0.9032        15\n",
      "\n",
      "    accuracy                         0.9450       200\n",
      "   macro avg     0.9483    0.9454    0.9434       200\n",
      "weighted avg     0.9475    0.9450    0.9427       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Best Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.7391    0.8500        23\n",
      "    অর্থনীতি     1.0000    1.0000    1.0000        25\n",
      "         আইন     0.9310    1.0000    0.9643        27\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        32\n",
      "     বিজ্ঞান     0.9130    1.0000    0.9545        21\n",
      "      বিনোদন     1.0000    1.0000    1.0000         7\n",
      "     রাজনীতি     0.9643    0.9643    0.9643        28\n",
      "  লাইফস্টাইল     0.9565    1.0000    0.9778        22\n",
      "      শিক্ষা     0.8750    0.9333    0.9032        15\n",
      "\n",
      "    accuracy                         0.9600       200\n",
      "   macro avg     0.9600    0.9596    0.9571       200\n",
      "weighted avg     0.9624    0.9600    0.9585       200\n",
      "\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Train Loss: 1.1724\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.9412    0.9697        17\n",
      "    অর্থনীতি     1.0000    0.9167    0.9565        24\n",
      "         আইন     1.0000    1.0000    1.0000        21\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        22\n",
      "     বিজ্ঞান     0.9583    1.0000    0.9787        23\n",
      "      বিনোদন     0.9259    1.0000    0.9615        25\n",
      "     রাজনীতি     1.0000    1.0000    1.0000        20\n",
      "  লাইফস্টাইল     1.0000    1.0000    1.0000        26\n",
      "      শিক্ষা     0.9545    0.9545    0.9545        22\n",
      "\n",
      "    accuracy                         0.9800       200\n",
      "   macro avg     0.9821    0.9792    0.9801       200\n",
      "weighted avg     0.9809    0.9800    0.9800       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "Train Loss: 0.6008\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.9412    0.9697        17\n",
      "    অর্থনীতি     1.0000    0.8333    0.9091        24\n",
      "         আইন     1.0000    1.0000    1.0000        21\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        22\n",
      "     বিজ্ঞান     0.8846    1.0000    0.9388        23\n",
      "      বিনোদন     0.9259    1.0000    0.9615        25\n",
      "     রাজনীতি     1.0000    1.0000    1.0000        20\n",
      "  লাইফস্টাইল     1.0000    1.0000    1.0000        26\n",
      "      শিক্ষা     0.9545    0.9545    0.9545        22\n",
      "\n",
      "    accuracy                         0.9700       200\n",
      "   macro avg     0.9739    0.9699    0.9704       200\n",
      "weighted avg     0.9725    0.9700    0.9697       200\n",
      "\n",
      "Fold 5 Best Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    অন্যান্য     1.0000    0.9412    0.9697        17\n",
      "    অর্থনীতি     1.0000    0.9167    0.9565        24\n",
      "         আইন     1.0000    1.0000    1.0000        21\n",
      "    খেলাধুলা     1.0000    1.0000    1.0000        22\n",
      "     বিজ্ঞান     0.9583    1.0000    0.9787        23\n",
      "      বিনোদন     0.9259    1.0000    0.9615        25\n",
      "     রাজনীতি     1.0000    1.0000    1.0000        20\n",
      "  লাইফস্টাইল     1.0000    1.0000    1.0000        26\n",
      "      শিক্ষা     0.9545    0.9545    0.9545        22\n",
      "\n",
      "    accuracy                         0.9800       200\n",
      "   macro avg     0.9821    0.9792    0.9801       200\n",
      "weighted avg     0.9809    0.9800    0.9800       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置超参数\n",
    "num_epochs = 2\n",
    "batch_size =16\n",
    "learning_rate = 2e-5\n",
    "hidden_size = 128\n",
    "num_classes = len(label_map)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# 存储所有fold的性能指标\n",
    "all_reports = []\n",
    "\n",
    "# K-Fold交叉验证\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(data)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "    \n",
    "    train_data = data.iloc[train_idx]\n",
    "    val_data = data.iloc[val_idx]\n",
    "\n",
    "    train_texts = train_data['body'].tolist()\n",
    "    train_labels = train_data['category1'].map(label_map).tolist()\n",
    "    val_texts = val_data['body'].tolist()\n",
    "    val_labels = val_data['category1'].map(label_map).tolist()\n",
    "\n",
    "    train_dataset = NewsDataset(train_texts, train_labels, tokenizer)\n",
    "    val_dataset = NewsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = LSTMClassifier(bert_model, hidden_size, num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "        val_report = evaluate(model, val_loader, device, label_map)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f}')\n",
    "        print('Validation Report:')\n",
    "        print(val_report)\n",
    "\n",
    "        val_loss = 1 - float(val_report.split('\\n')[-2].split()[-2])  # 提取验证集损失\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'best_model_fold_{fold + 1}.pth')\n",
    "\n",
    "    # 在每个fold结束后,评估最佳模型在验证集上的性能\n",
    "    best_model = LSTMClassifier(bert_model, hidden_size, num_classes)\n",
    "    best_model.load_state_dict(torch.load(f'best_model_fold_{fold + 1}.pth'))\n",
    "    best_model.to(device)\n",
    "    val_report = evaluate(best_model, val_loader, device, label_map)\n",
    "    all_reports.append(val_report)\n",
    "\n",
    "    print(f'Fold {fold + 1} Best Validation Report:')\n",
    "    print(val_report)\n",
    "    print()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de866a-27b6-4967-9224-f1c50ed8f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算并打印所有fold的平均性能\n",
    "print('Average Performance Across All Folds:')\n",
    "avg_report = pd.DataFrame([report.split() for report in all_reports]).mean(axis=0)\n",
    "avg_report = '\\n'.join([('{:<10}'.format(col) + '{:.4f}'.format(val)) for col, val in zip(avg_report.index, avg_report.values)])\n",
    "print(avg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93c36d6-5b07-4e24-8239-001acce72329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['              precision    recall  f1-score   support\\n\\n    অন্যান্য     1.0000    0.7222    0.8387        18\\n    অর্থনীতি     0.9630    0.8966    0.9286        29\\n         আইন     0.8667    0.9630    0.9123        27\\n    খেলাধুলা     0.9583    1.0000    0.9787        23\\n     বিজ্ঞান     0.9200    0.9583    0.9388        24\\n      বিনোদন     0.9545    1.0000    0.9767        21\\n     রাজনীতি     0.9615    1.0000    0.9804        25\\n  লাইফস্টাইল     0.9412    0.9412    0.9412        17\\n      শিক্ষা     0.8750    0.8750    0.8750        16\\n\\n    accuracy                         0.9350       200\\n   macro avg     0.9378    0.9285    0.9300       200\\nweighted avg     0.9377    0.9350    0.9336       200\\n', '              precision    recall  f1-score   support\\n\\n    অন্যান্য     1.0000    0.8696    0.9302        23\\n    অর্থনীতি     1.0000    0.9000    0.9474        20\\n         আইন     1.0000    1.0000    1.0000        22\\n    খেলাধুলা     1.0000    1.0000    1.0000        25\\n     বিজ্ঞান     0.9286    0.9286    0.9286        14\\n      বিনোদন     1.0000    1.0000    1.0000        22\\n     রাজনীতি     0.9200    1.0000    0.9583        23\\n  লাইফস্টাইল     0.8438    0.9643    0.9000        28\\n      শিক্ষা     1.0000    0.9565    0.9778        23\\n\\n    accuracy                         0.9600       200\\n   macro avg     0.9658    0.9577    0.9603       200\\nweighted avg     0.9639    0.9600    0.9604       200\\n', '              precision    recall  f1-score   support\\n\\n    অন্যান্য     0.9500    0.7917    0.8636        24\\n    অর্থনীতি     0.9048    0.9500    0.9268        20\\n         আইন     0.9565    1.0000    0.9778        22\\n    খেলাধুলা     1.0000    1.0000    1.0000        19\\n     বিজ্ঞান     0.9000    0.9000    0.9000        20\\n      বিনোদন     1.0000    0.9500    0.9744        20\\n     রাজনীতি     0.8800    1.0000    0.9362        22\\n  লাইফস্টাইল     0.9524    0.9524    0.9524        21\\n      শিক্ষা     0.9375    0.9375    0.9375        32\\n\\n    accuracy                         0.9400       200\\n   macro avg     0.9424    0.9424    0.9410       200\\nweighted avg     0.9415    0.9400    0.9393       200\\n', '              precision    recall  f1-score   support\\n\\n    অন্যান্য     1.0000    0.7391    0.8500        23\\n    অর্থনীতি     1.0000    1.0000    1.0000        25\\n         আইন     0.9310    1.0000    0.9643        27\\n    খেলাধুলা     1.0000    1.0000    1.0000        32\\n     বিজ্ঞান     0.9130    1.0000    0.9545        21\\n      বিনোদন     1.0000    1.0000    1.0000         7\\n     রাজনীতি     0.9643    0.9643    0.9643        28\\n  লাইফস্টাইল     0.9565    1.0000    0.9778        22\\n      শিক্ষা     0.8750    0.9333    0.9032        15\\n\\n    accuracy                         0.9600       200\\n   macro avg     0.9600    0.9596    0.9571       200\\nweighted avg     0.9624    0.9600    0.9585       200\\n', '              precision    recall  f1-score   support\\n\\n    অন্যান্য     1.0000    0.9412    0.9697        17\\n    অর্থনীতি     1.0000    0.9167    0.9565        24\\n         আইন     1.0000    1.0000    1.0000        21\\n    খেলাধুলা     1.0000    1.0000    1.0000        22\\n     বিজ্ঞান     0.9583    1.0000    0.9787        23\\n      বিনোদন     0.9259    1.0000    0.9615        25\\n     রাজনীতি     1.0000    1.0000    1.0000        20\\n  লাইফস্টাইল     1.0000    1.0000    1.0000        26\\n      শিক্ষা     0.9545    0.9545    0.9545        22\\n\\n    accuracy                         0.9800       200\\n   macro avg     0.9821    0.9792    0.9801       200\\nweighted avg     0.9809    0.9800    0.9800       200\\n']\n"
     ]
    }
   ],
   "source": [
    "print(all_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9de40c7-3b83-479a-9506-bd1e1f5ff299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Performance Across All Folds:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(cls_values)\n\u001b[1;32m     17\u001b[0m avg_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m cls_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msup\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, (prec, rec, f1, sup) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(label_map\u001b[38;5;241m.\u001b[39mkeys(), avg_values)])\n\u001b[1;32m     20\u001b[0m avg_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28mfloat\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m all_reports \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m report\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line])\n\u001b[1;32m     21\u001b[0m avg_macro \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28mfloat\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m all_reports \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m report\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro avg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line])\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(cls_values)\n\u001b[1;32m     17\u001b[0m avg_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m cls_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msup\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, (prec, rec, f1, sup) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(label_map\u001b[38;5;241m.\u001b[39mkeys(), avg_values)])\n\u001b[1;32m     20\u001b[0m avg_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28mfloat\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m all_reports \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m report\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line])\n\u001b[1;32m     21\u001b[0m avg_macro \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28mfloat\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m all_reports \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m report\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro avg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line])\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "# 计算并打印所有fold的平均性能\n",
    "print('Average Performance Across All Folds:')\n",
    "all_lines = [report.split('\\n') for report in all_reports]\n",
    "header = all_lines[0][0] + '\\t' + '\\t'.join([line.strip() for line in all_lines[0][-4:]])\n",
    "\n",
    "values = []\n",
    "for report in all_reports:\n",
    "    lines = report.split('\\n')\n",
    "    cls_lines = lines[1:-5]\n",
    "    cls_values = []\n",
    "    for line in cls_lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 5:\n",
    "            cls_values.append([float(val) if val != 'nan' else 0.0 for val in parts[1:-1]])\n",
    "    values.append(cls_values)\n",
    "\n",
    "avg_values = np.mean(values, axis=0)\n",
    "cls_report = '\\n'.join([f'{cls}\\t{prec:.4f}\\t{rec:.4f}\\t{f1:.4f}\\t{sup:.0f}' for cls, (prec, rec, f1, sup) in zip(label_map.keys(), avg_values)])\n",
    "\n",
    "avg_acc = np.mean([float(line.split()[-2]) for report in all_reports for line in report.split('\\n') if 'accuracy' in line])\n",
    "avg_macro = np.mean([float(line.split()[-2]) for report in all_reports for line in report.split('\\n') if 'macro avg' in line])\n",
    "avg_weighted = np.mean([float(line.split()[-2]) for report in all_reports for line in report.split('\\n') if 'weighted avg' in line])\n",
    "\n",
    "avg_report = header + '\\n' + cls_report + '\\n' + f\"accuracy\\t{avg_acc:.4f}\\nmacro avg\\t{avg_macro:.4f}\\nweighted avg\\t{avg_weighted:.4f}\"\n",
    "print(avg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de78b5a-94c2-49fc-b23d-2addc9e05be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-default",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
