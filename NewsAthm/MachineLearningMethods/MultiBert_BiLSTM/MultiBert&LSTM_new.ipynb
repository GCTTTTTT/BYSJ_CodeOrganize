{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea37124-b1a2-4009-84da-469573a54955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7deb77-4667-48a2-a7d9-899b55fd3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 设置随机种子\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 加载数据\n",
    "file_path = '../datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled_Example.csv'\n",
    "# file_path = '../datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new_undersampled.csv'\n",
    "\n",
    "data = pd.read_csv(file_path,low_memory=False,lineterminator=\"\\n\")\n",
    "\n",
    "# 加载BERT tokenizer和模型\n",
    "model_name = '../bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "bert_model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# 将模型移动到GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2401d681-5171-43dd-a799-d66bb2a3db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集类\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 将孟加拉语类别转换为数字标签\n",
    "label_map = {label: i for i, label in enumerate(data['category1'].unique())}\n",
    "labels = data['category1'].map(label_map).tolist()\n",
    "\n",
    "# 定义LSTM分类器\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size, num_classes, num_layers=1, bidirectional=True, dropout=0.5):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(bert_model.config.hidden_size, hidden_size, num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * (2 if bidirectional else 1), num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        lstm_output, _ = self.lstm(last_hidden_state)\n",
    "        lstm_output = self.dropout(lstm_output[:, -1, :])\n",
    "        logits = self.fc(lstm_output)\n",
    "        return logits\n",
    "\n",
    "# 定义训练和评估函数\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(data_loader, desc='Training', leave=False)\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        print(logits)\n",
    "        print(logits.shape)\n",
    "        print(labels)\n",
    "        print(labels.size())\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate(model, data_loader, device, label_map):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            batch_predictions = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(batch_predictions.tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "\n",
    "    label_map_inv = {v: k for k, v in label_map.items()}\n",
    "    predictions = [label_map_inv[i] for i in predictions]\n",
    "    true_labels = [label_map_inv[i] for i in true_labels]\n",
    "\n",
    "    report = classification_report(true_labels, predictions, digits=4)\n",
    "    return report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d140bde-ec6a-4073-976d-debadd233b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3022,  0.0833,  0.0065,  0.1480,  0.0466,  0.0124,  0.4299,  0.2868,\n",
      "         -0.1390],\n",
      "        [-0.2332,  0.0940,  0.0132,  0.3554,  0.2112, -0.1020,  0.2920,  0.1797,\n",
      "         -0.0688],\n",
      "        [-0.0917,  0.0694,  0.0541,  0.1740,  0.0213, -0.1568,  0.1943,  0.0707,\n",
      "          0.0640],\n",
      "        [-0.2144, -0.0488,  0.0340,  0.1591,  0.2035, -0.1157,  0.0993,  0.0322,\n",
      "          0.0656]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([2, 3, 8, 1], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 2/200 [00:00<01:24,  2.33it/s, loss=2.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2687,  0.1010,  0.3368,  0.1046, -0.0022,  0.0440,  0.0258,  0.0593,\n",
      "          0.0848],\n",
      "        [-0.1179,  0.1243,  0.2572, -0.1599,  0.1176, -0.0150, -0.0968, -0.0684,\n",
      "          0.3300],\n",
      "        [-0.0784,  0.2030,  0.2357,  0.0205, -0.2039, -0.0344,  0.1700,  0.0121,\n",
      "          0.1421],\n",
      "        [-0.1622,  0.1535,  0.2404, -0.1118,  0.1789,  0.0450, -0.0150, -0.0622,\n",
      "          0.0926]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([1, 6, 1, 6], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 3/200 [00:01<01:12,  2.73it/s, loss=2.28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2286,  0.2019,  0.2686,  0.0574, -0.1208,  0.0037,  0.1854,  0.0259,\n",
      "          0.2144],\n",
      "        [-0.1474,  0.3577,  0.3038,  0.0123,  0.1107,  0.2241,  0.0065, -0.0138,\n",
      "          0.0915],\n",
      "        [-0.3490,  0.2145,  0.2209,  0.1633,  0.0556, -0.2043,  0.3013,  0.0208,\n",
      "          0.0973],\n",
      "        [-0.1491,  0.2287,  0.4997,  0.0944, -0.0322,  0.0188, -0.0251,  0.0451,\n",
      "          0.1994]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([1, 5, 0, 6], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 4/200 [00:01<00:58,  3.33it/s, loss=2.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2380,  0.4346,  0.2587, -0.1027, -0.0122,  0.1008,  0.1194, -0.0763,\n",
      "          0.2470],\n",
      "        [-0.1151,  0.1880,  0.1389,  0.2970,  0.1727, -0.1997,  0.3606,  0.0591,\n",
      "         -0.0015],\n",
      "        [-0.5138,  0.6042,  0.3456,  0.2407, -0.1979,  0.0239,  0.0901, -0.2281,\n",
      "          0.2427],\n",
      "        [-0.0989,  0.2548,  0.3308, -0.0437, -0.0569,  0.0722,  0.1141, -0.1284,\n",
      "          0.1068]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([4, 2, 6, 5], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 5/200 [00:01<00:59,  3.29it/s, loss=2.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2054,  0.2848,  0.3025, -0.0130, -0.0216, -0.1902,  0.0162, -0.0777,\n",
      "          0.1812],\n",
      "        [-0.0150,  0.2654,  0.0559,  0.0792,  0.0850, -0.0616,  0.2383, -0.0532,\n",
      "          0.1975],\n",
      "        [-0.1311,  0.3063, -0.0088,  0.0575,  0.1229,  0.0144,  0.2228, -0.1931,\n",
      "          0.2794],\n",
      "        [-0.3107,  0.3073,  0.3583, -0.2052, -0.1578, -0.0717,  0.0809, -0.0694,\n",
      "          0.0727]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([4, 5, 1, 3], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 6/200 [00:02<00:57,  3.35it/s, loss=2.08]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0833,  0.4157,  0.0284,  0.0226,  0.0192, -0.0251,  0.1990, -0.0438,\n",
      "          0.0862],\n",
      "        [-0.1246,  0.5749,  0.1940, -0.1322, -0.2166, -0.0891,  0.2305, -0.1457,\n",
      "         -0.1612],\n",
      "        [-0.1397,  0.3813, -0.0458,  0.0700,  0.0491,  0.1311,  0.2774, -0.1228,\n",
      "          0.2213],\n",
      "        [-0.0088,  0.4093,  0.1601,  0.2451,  0.1524, -0.0556,  0.2062, -0.2057,\n",
      "          0.1380]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([7, 1, 5, 4], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 7/200 [00:02<00:51,  3.78it/s, loss=2.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3521,  0.5293,  0.3024, -0.0974, -0.0960,  0.0442,  0.2811, -0.2341,\n",
      "          0.0454],\n",
      "        [-0.0665,  0.3435,  0.1568, -0.0849, -0.2197, -0.0277,  0.3396, -0.1481,\n",
      "          0.0390],\n",
      "        [-0.3162,  0.4119,  0.2874,  0.0932,  0.0056,  0.1952,  0.2249, -0.1801,\n",
      "          0.0741],\n",
      "        [-0.2278,  0.3950,  0.1455,  0.0036,  0.0344,  0.1308,  0.2193,  0.0081,\n",
      "         -0.1309]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([5, 3, 2, 5], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 8/200 [00:02<00:54,  3.51it/s, loss=2.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2588,  0.6145,  0.1416,  0.1329, -0.0047,  0.1537,  0.1461,  0.0084,\n",
      "         -0.1365],\n",
      "        [-0.2578,  0.5327,  0.0751, -0.1927, -0.0879,  0.0695,  0.1291, -0.1837,\n",
      "         -0.1107],\n",
      "        [-0.1657,  0.5251,  0.2247, -0.0010,  0.0619,  0.2417,  0.2548, -0.2410,\n",
      "          0.1566],\n",
      "        [-0.1229,  0.3582,  0.0125,  0.2310, -0.0045,  0.0852,  0.3606,  0.0138,\n",
      "          0.0414]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([1, 3, 5, 5], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 9/200 [00:02<00:55,  3.43it/s, loss=2.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1568,  0.5515,  0.0927, -0.1358, -0.1779,  0.2404,  0.0581, -0.2677,\n",
      "         -0.0589],\n",
      "        [-0.1156,  0.4762,  0.1693, -0.1553, -0.1022,  0.0706,  0.0160, -0.1276,\n",
      "          0.0773],\n",
      "        [-0.3198,  0.5965,  0.2838,  0.0065,  0.0643,  0.1926,  0.1077, -0.0839,\n",
      "          0.0312],\n",
      "        [-0.2653,  0.4384,  0.0347,  0.0183,  0.0614,  0.1772,  0.2749, -0.0702,\n",
      "          0.1560]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([2, 1, 7, 8], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 10/200 [00:03<00:50,  3.75it/s, loss=2.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2918,  0.4906,  0.0758,  0.0894, -0.1356,  0.4015,  0.1698, -0.0931,\n",
      "          0.1828],\n",
      "        [-0.1186,  0.6541,  0.2175, -0.0094, -0.0836, -0.0531,  0.2820, -0.1058,\n",
      "          0.0307],\n",
      "        [-0.2684,  0.6489,  0.1535, -0.0321, -0.2982,  0.4449,  0.0524,  0.0291,\n",
      "         -0.0883],\n",
      "        [-0.1267,  0.2733, -0.0661,  0.2930,  0.0181,  0.1761,  0.3565, -0.0956,\n",
      "         -0.0351]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([3, 2, 3, 3], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 11/200 [00:03<00:54,  3.50it/s, loss=2.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2578,  0.3469,  0.1035, -0.0457,  0.0708,  0.1950,  0.1549, -0.1766,\n",
      "          0.1610],\n",
      "        [-0.3186,  0.6412,  0.2105, -0.1525, -0.1805,  0.1875,  0.0190, -0.0213,\n",
      "         -0.0660],\n",
      "        [-0.1485,  0.4962, -0.0175,  0.1001, -0.1821,  0.2045,  0.3444, -0.1124,\n",
      "         -0.1204],\n",
      "        [-0.1466,  0.2048,  0.1587, -0.0117,  0.1133,  0.0967,  0.2760, -0.1310,\n",
      "          0.0364]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([4, 1, 2, 2], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 12/200 [00:03<00:53,  3.53it/s, loss=2.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2625,  0.6281,  0.0587,  0.1010, -0.4542,  0.2234,  0.1844, -0.3316,\n",
      "          0.0317],\n",
      "        [-0.2302,  0.3120,  0.0009,  0.0500, -0.0787,  0.1147, -0.0076, -0.1297,\n",
      "         -0.0503],\n",
      "        [-0.2465,  0.5599,  0.0722,  0.0747, -0.1071,  0.3565,  0.0248, -0.0236,\n",
      "         -0.1089],\n",
      "        [-0.1297,  0.5726,  0.0674, -0.0417,  0.0574,  0.2077,  0.2189,  0.0056,\n",
      "         -0.0384]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([6, 0, 0, 0], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 13/200 [00:03<00:46,  4.00it/s, loss=1.98]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0594,  0.6077,  0.2570,  0.1881, -0.2054,  0.3060,  0.0954, -0.2318,\n",
      "          0.0077],\n",
      "        [-0.2946,  0.4427,  0.2310, -0.0410, -0.0397,  0.1853,  0.1558, -0.2539,\n",
      "         -0.2021],\n",
      "        [-0.3950,  0.6884,  0.1577, -0.0104, -0.2228, -0.0323, -0.1365, -0.3360,\n",
      "         -0.1243],\n",
      "        [-0.3430,  0.4128,  0.1164, -0.0662,  0.0960,  0.1341,  0.1337, -0.1844,\n",
      "          0.0861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([1, 6, 1, 0], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 14/200 [00:04<00:49,  3.72it/s, loss=2]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0518,  0.2803,  0.1355,  0.0638, -0.2072,  0.1144, -0.0365, -0.1716,\n",
      "         -0.1923],\n",
      "        [-0.3280,  0.4375,  0.0431,  0.0720, -0.3322,  0.2903,  0.2488, -0.2121,\n",
      "         -0.1232],\n",
      "        [-0.1481,  0.4140,  0.0762,  0.2353,  0.0520,  0.0563,  0.2969, -0.0537,\n",
      "          0.0757],\n",
      "        [-0.0747,  0.5197,  0.1339,  0.3300, -0.0035,  0.1599,  0.3141, -0.1548,\n",
      "         -0.1774]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([1, 1, 3, 5], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 15/200 [00:04<00:52,  3.52it/s, loss=2.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3062,  0.5322, -0.1378,  0.1024, -0.1127,  0.1146,  0.0540, -0.1489,\n",
      "         -0.1714],\n",
      "        [-0.1680,  0.5568, -0.0142,  0.0042, -0.0277,  0.2114,  0.2458, -0.1116,\n",
      "          0.0825],\n",
      "        [-0.1050,  0.3927,  0.0715, -0.0378, -0.0530,  0.2183,  0.0212, -0.0366,\n",
      "         -0.0421],\n",
      "        [-0.3098,  0.5896,  0.3647,  0.1856, -0.3830,  0.2422,  0.3062, -0.2146,\n",
      "         -0.0715]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([6, 4, 3, 3], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 16/200 [00:04<00:46,  3.95it/s, loss=2.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1569,  0.3638,  0.0133, -0.0971,  0.0168,  0.3177,  0.0522,  0.0483,\n",
      "          0.0514],\n",
      "        [-0.2736,  0.5894,  0.2203,  0.1403, -0.2083,  0.2270,  0.1125, -0.3228,\n",
      "         -0.0351],\n",
      "        [-0.1209,  0.2447,  0.0261,  0.3206, -0.1683, -0.0916,  0.2935, -0.3264,\n",
      "         -0.2111],\n",
      "        [-0.3982,  0.7063,  0.1766,  0.0633, -0.3438,  0.3040,  0.2869, -0.2735,\n",
      "         -0.0540]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([5, 1, 7, 8], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 17/200 [00:04<00:50,  3.65it/s, loss=2.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0643,  0.8043,  0.1632,  0.3754, -0.3566,  0.4638,  0.1574,  0.0311,\n",
      "         -0.1391],\n",
      "        [-0.1575,  0.4763,  0.1774,  0.2659, -0.2215,  0.4101,  0.1701, -0.2461,\n",
      "         -0.1117],\n",
      "        [-0.2635,  0.8364,  0.2838,  0.2292, -0.3670,  0.2296,  0.0699, -0.2177,\n",
      "         -0.0720],\n",
      "        [-0.2916,  0.4238,  0.3105,  0.0343, -0.4097,  0.0597,  0.2250, -0.2320,\n",
      "         -0.1803]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([0, 6, 6, 7], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 18/200 [00:05<00:51,  3.56it/s, loss=2.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4510,  0.6912,  0.3422,  0.0212, -0.3068,  0.2498,  0.1062, -0.3254,\n",
      "         -0.1890],\n",
      "        [-0.1542,  0.4360,  0.1310,  0.0566,  0.0412,  0.2739,  0.3082, -0.1216,\n",
      "          0.0404],\n",
      "        [-0.1382,  0.2076,  0.0457, -0.0652, -0.0047,  0.3000,  0.1458, -0.1220,\n",
      "         -0.0087],\n",
      "        [-0.3349,  0.7580,  0.2019,  0.1891, -0.2097,  0.6321, -0.0194, -0.0595,\n",
      "          0.0425]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([4, 6, 2, 5], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 19/200 [00:05<00:44,  4.11it/s, loss=2.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3602,  0.3585,  0.1841, -0.0130, -0.2256,  0.0487,  0.1710, -0.2745,\n",
      "         -0.0035],\n",
      "        [-0.1484,  0.7172,  0.1484,  0.2972, -0.2441,  0.2913,  0.3247, -0.1673,\n",
      "         -0.3037],\n",
      "        [-0.1658,  0.3051,  0.0714,  0.2631, -0.2827,  0.2755,  0.2113, -0.1202,\n",
      "         -0.2443],\n",
      "        [-0.0643,  0.5013,  0.0598,  0.2971, -0.0166,  0.4549,  0.1943, -0.0339,\n",
      "         -0.0042]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([8, 3, 7, 4], device='cuda:0')\n",
      "torch.Size([4])\n",
      "tensor([[-0.2302,  0.2968,  0.0109,  0.0689,  0.2242,  0.0865,  0.2129, -0.1457,\n",
      "          0.0824],\n",
      "        [-0.4363,  0.3731,  0.0483,  0.1068,  0.0414,  0.1624,  0.2452, -0.2163,\n",
      "          0.0848],\n",
      "        [-0.2452,  0.6634,  0.2592,  0.0864, -0.0946,  0.2095,  0.4221, -0.1153,\n",
      "         -0.0099],\n",
      "        [ 0.0015,  0.5014,  0.3063,  0.1471, -0.2404,  0.5820,  0.0873, -0.3201,\n",
      "         -0.0947]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([6, 4, 7, 8], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 21/200 [00:06<00:49,  3.59it/s, loss=2.38]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2578,  0.4973,  0.2203,  0.3343, -0.2428,  0.1570,  0.1546, -0.0083,\n",
      "         -0.2099],\n",
      "        [-0.1109,  0.3372,  0.0208,  0.2043, -0.1945,  0.3846,  0.1782, -0.0648,\n",
      "         -0.1484],\n",
      "        [-0.0906,  0.7579,  0.1916,  0.2716, -0.2421,  0.4335,  0.3112, -0.2567,\n",
      "          0.0317],\n",
      "        [-0.2120,  0.5395,  0.2111,  0.2034, -0.4685,  0.5433,  0.2333, -0.0853,\n",
      "         -0.0630]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([4, 9])\n",
      "tensor([3, 7, 7, 0], device='cuda:0')\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 39\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     val_report \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device, label_map)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     66\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 69\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[0;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     last_hidden_state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m     53\u001b[0m     lstm_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(last_hidden_state)\n",
      "File \u001b[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:960\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn_if_padding_and_no_attention_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/transformers/modeling_utils.py:4509\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4504\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4505\u001b[0m \u001b[38;5;124;03mShows a one-time warning if the input_ids appear to contain padding and no attention mask was given.\u001b[39;00m\n\u001b[1;32m   4506\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4508\u001b[0m \u001b[38;5;66;03m# Skip the check during tracing.\u001b[39;00m\n\u001b[0;32m-> 4509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_fx_proxy(input_ids) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mis_torchdynamo_compiling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   4510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   4512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/transformers/utils/import_utils.py:524\u001b[0m, in \u001b[0;36mis_torchdynamo_compiling\u001b[0;34m()\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdynamo\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dynamo\u001b[38;5;241m.\u001b[39mis_compiling()\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:971\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:914\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1407\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1379\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1534\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:123\u001b[0m, in \u001b[0;36m_path_join\u001b[0;34m(*path_parts)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 设置超参数\n",
    "num_epochs = 2\n",
    "batch_size =4\n",
    "learning_rate = 2e-5\n",
    "hidden_size = 128\n",
    "num_classes = len(label_map)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# 存储所有fold的性能指标\n",
    "all_reports = []\n",
    "\n",
    "# K-Fold交叉验证\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(data)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "    \n",
    "    train_data = data.iloc[train_idx]\n",
    "    val_data = data.iloc[val_idx]\n",
    "\n",
    "    train_texts = train_data['body'].tolist()\n",
    "    train_labels = train_data['category1'].map(label_map).tolist()\n",
    "    val_texts = val_data['body'].tolist()\n",
    "    val_labels = val_data['category1'].map(label_map).tolist()\n",
    "\n",
    "    train_dataset = NewsDataset(train_texts, train_labels, tokenizer)\n",
    "    val_dataset = NewsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = LSTMClassifier(bert_model, hidden_size, num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "        val_report = evaluate(model, val_loader, device, label_map)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f}')\n",
    "        print('Validation Report:')\n",
    "        print(val_report)\n",
    "\n",
    "        val_loss = 1 - float(val_report.split('\\n')[-2].split()[-2])  # 提取验证集损失\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'besta_model_fold_{fold + 1}.pth')\n",
    "\n",
    "    # 在每个fold结束后,评估最佳模型在验证集上的性能\n",
    "    best_model = LSTMClassifier(bert_model, hidden_size, num_classes)\n",
    "    best_model.load_state_dict(torch.load(f'besta_model_fold_{fold + 1}.pth'))\n",
    "    best_model.to(device)\n",
    "    val_report = evaluate(best_model, val_loader, device, label_map)\n",
    "    all_reports.append(val_report)\n",
    "\n",
    "    print(f'Fold {fold + 1} Best Validation Report:')\n",
    "    print(val_report)\n",
    "    print()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de866a-27b6-4967-9224-f1c50ed8f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算并打印所有fold的平均性能\n",
    "print('Average Performance Across All Folds:')\n",
    "avg_report = pd.DataFrame([report.split() for report in all_reports]).mean(axis=0)\n",
    "avg_report = '\\n'.join([('{:<10}'.format(col) + '{:.4f}'.format(val)) for col, val in zip(avg_report.index, avg_report.values)])\n",
    "print(avg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93c36d6-5b07-4e24-8239-001acce72329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['              precision    recall  f1-score   support\\n\\n    অন্যান্য     1.0000    0.7222    0.8387        18\\n    অর্থনীতি     0.9630    0.8966    0.9286        29\\n         আইন     0.8667    0.9630    0.9123        27\\n    খেলাধুলা     0.9583    1.0000    0.9787        23\\n     বিজ্ঞান     0.9200    0.9583    0.9388        24\\n      বিনোদন     0.9545    1.0000    0.9767        21\\n     রাজনীতি     0.9615    1.0000    0.9804        25\\n  লাইফস্টাইল     0.9412    0.9412    0.9412        17\\n      শিক্ষা     0.8750    0.8750    0.8750        16\\n\\n    accuracy                         0.9350       200\\n   macro avg     0.9378    0.9285    0.9300       200\\nweighted avg     0.9377    0.9350    0.9336       200\\n', '              precision    recall  f1-score   support\\n\\n    অন্যান্য     1.0000    0.8696    0.9302        23\\n    অর্থনীতি     1.0000    0.9000    0.9474        20\\n         আইন     1.0000    1.0000    1.0000        22\\n    খেলাধুলা     1.0000    1.0000    1.0000        25\\n     বিজ্ঞান     0.9286    0.9286    0.9286        14\\n      বিনোদন     1.0000    1.0000    1.0000        22\\n     রাজনীতি     0.9200    1.0000    0.9583        23\\n  লাইফস্টাইল     0.8438    0.9643    0.9000        28\\n      শিক্ষা     1.0000    0.9565    0.9778        23\\n\\n    accuracy                         0.9600       200\\n   macro avg     0.9658    0.9577    0.9603       200\\nweighted avg     0.9639    0.9600    0.9604       200\\n', '              precision    recall  f1-score   support\\n\\n    অন্যান্য     0.9500    0.7917    0.8636        24\\n    অর্থনীতি     0.9048    0.9500    0.9268        20\\n         আইন     0.9565    1.0000    0.9778        22\\n    খেলাধুলা     1.0000    1.0000    1.0000        19\\n     বিজ্ঞান     0.9000    0.9000    0.9000        20\\n      বিনোদন     1.0000    0.9500    0.9744        20\\n     রাজনীতি     0.8800    1.0000    0.9362        22\\n  লাইফস্টাইল     0.9524    0.9524    0.9524        21\\n      শিক্ষা     0.9375    0.9375    0.9375        32\\n\\n    accuracy                         0.9400       200\\n   macro avg     0.9424    0.9424    0.9410       200\\nweighted avg     0.9415    0.9400    0.9393       200\\n', '              precision    recall  f1-score   support\\n\\n    অন্যান্য     1.0000    0.7391    0.8500        23\\n    অর্থনীতি     1.0000    1.0000    1.0000        25\\n         আইন     0.9310    1.0000    0.9643        27\\n    খেলাধুলা     1.0000    1.0000    1.0000        32\\n     বিজ্ঞান     0.9130    1.0000    0.9545        21\\n      বিনোদন     1.0000    1.0000    1.0000         7\\n     রাজনীতি     0.9643    0.9643    0.9643        28\\n  লাইফস্টাইল     0.9565    1.0000    0.9778        22\\n      শিক্ষা     0.8750    0.9333    0.9032        15\\n\\n    accuracy                         0.9600       200\\n   macro avg     0.9600    0.9596    0.9571       200\\nweighted avg     0.9624    0.9600    0.9585       200\\n', '              precision    recall  f1-score   support\\n\\n    অন্যান্য     1.0000    0.9412    0.9697        17\\n    অর্থনীতি     1.0000    0.9167    0.9565        24\\n         আইন     1.0000    1.0000    1.0000        21\\n    খেলাধুলা     1.0000    1.0000    1.0000        22\\n     বিজ্ঞান     0.9583    1.0000    0.9787        23\\n      বিনোদন     0.9259    1.0000    0.9615        25\\n     রাজনীতি     1.0000    1.0000    1.0000        20\\n  লাইফস্টাইল     1.0000    1.0000    1.0000        26\\n      শিক্ষা     0.9545    0.9545    0.9545        22\\n\\n    accuracy                         0.9800       200\\n   macro avg     0.9821    0.9792    0.9801       200\\nweighted avg     0.9809    0.9800    0.9800       200\\n']\n"
     ]
    }
   ],
   "source": [
    "print(all_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9de40c7-3b83-479a-9506-bd1e1f5ff299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Performance Across All Folds:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(cls_values)\n\u001b[1;32m     17\u001b[0m avg_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m cls_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msup\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, (prec, rec, f1, sup) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(label_map\u001b[38;5;241m.\u001b[39mkeys(), avg_values)])\n\u001b[1;32m     20\u001b[0m avg_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28mfloat\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m all_reports \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m report\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line])\n\u001b[1;32m     21\u001b[0m avg_macro \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28mfloat\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m all_reports \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m report\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro avg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line])\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(cls_values)\n\u001b[1;32m     17\u001b[0m avg_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m cls_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msup\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, (prec, rec, f1, sup) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(label_map\u001b[38;5;241m.\u001b[39mkeys(), avg_values)])\n\u001b[1;32m     20\u001b[0m avg_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28mfloat\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m all_reports \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m report\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line])\n\u001b[1;32m     21\u001b[0m avg_macro \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28mfloat\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m all_reports \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m report\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro avg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line])\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "# 计算并打印所有fold的平均性能\n",
    "print('Average Performance Across All Folds:')\n",
    "all_lines = [report.split('\\n') for report in all_reports]\n",
    "header = all_lines[0][0] + '\\t' + '\\t'.join([line.strip() for line in all_lines[0][-4:]])\n",
    "\n",
    "values = []\n",
    "for report in all_reports:\n",
    "    lines = report.split('\\n')\n",
    "    cls_lines = lines[1:-5]\n",
    "    cls_values = []\n",
    "    for line in cls_lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 5:\n",
    "            cls_values.append([float(val) if val != 'nan' else 0.0 for val in parts[1:-1]])\n",
    "    values.append(cls_values)\n",
    "\n",
    "avg_values = np.mean(values, axis=0)\n",
    "cls_report = '\\n'.join([f'{cls}\\t{prec:.4f}\\t{rec:.4f}\\t{f1:.4f}\\t{sup:.0f}' for cls, (prec, rec, f1, sup) in zip(label_map.keys(), avg_values)])\n",
    "\n",
    "avg_acc = np.mean([float(line.split()[-2]) for report in all_reports for line in report.split('\\n') if 'accuracy' in line])\n",
    "avg_macro = np.mean([float(line.split()[-2]) for report in all_reports for line in report.split('\\n') if 'macro avg' in line])\n",
    "avg_weighted = np.mean([float(line.split()[-2]) for report in all_reports for line in report.split('\\n') if 'weighted avg' in line])\n",
    "\n",
    "avg_report = header + '\\n' + cls_report + '\\n' + f\"accuracy\\t{avg_acc:.4f}\\nmacro avg\\t{avg_macro:.4f}\\nweighted avg\\t{avg_weighted:.4f}\"\n",
    "print(avg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de78b5a-94c2-49fc-b23d-2addc9e05be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-default",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
