{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c6390f-56ed-4cc8-a48b-e4db85b7ddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "2733\n",
      "已将类别进行合并处理，并写入到新的 CSV 文件中。\n"
     ]
    }
   ],
   "source": [
    "# 对去重，类别对应语料数大于3000的语料的类别进行合并\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# # 读取原始语料文件\n",
    "# corpus_file = 'deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "# corpus_df = pd.read_csv(corpus_file)\n",
    "\n",
    "# 定义类别合并规则\n",
    "category_mapping = {\n",
    "    'বাংলাদেশ': ['বাংলাদেশ', 'bangladesh'],\n",
    "    'জাতীয়': ['জাতীয়', 'national', 'দেশজুড়ে', 'দেশ', 'জাতীয়', 'সারাদেশ'],\n",
    "    'আন্তর্জাতিক': ['আন্তর্জাতিক', 'international', 'International'],\n",
    "    'সংবাদ': ['সংবাদ', 'খবর', 'News'],\n",
    "    'সর্বশেষ সংবাদ': ['আজকের পত্রিকা', 'সর্বশেষ সংবাদ'],\n",
    "    'খেলাধুলা': ['খেলাধুলা', 'sports', 'খেলা', 'খেলাধুলা ', 'ক্রিকেট', 'স্পোর্টস', 'Sports'],\n",
    "    'রাজনীতি': ['রাজনীতি', 'politics'],\n",
    "    'বিনোদন': ['বিনোদন ', 'entertainment', 'বিনোদন'],\n",
    "    'আর্কাইভ': ['আর্কাইভ', 'archive'],\n",
    "    'অর্থনীতি': ['অর্থনীতি', 'রাজধানী', 'অর্থ-বাণিজ্য', 'economics', 'অর্থ-উন্নয়ন', 'পুঁজিবাজার'],\n",
    "    'বৈশিষ্ট্যযুক্ত': ['Featured News', 'ফিচার'],\n",
    "    'আইন': ['অপরাধ', 'আদালত', 'আইন-বিচার', 'পুলিশ', 'আইন-বিচার ', 'অপরাধ ও দুর্নীতি'],\n",
    "    'শিক্ষা': ['শিক্ষা', 'শিক্ষা ', 'campus'],\n",
    "    'বিজ্ঞান': ['বিজ্ঞান ও তথ্যপ্রযুক্তি', 'তথ্য প্রযুক্তি'],\n",
    "    'লাইফস্টাইল': ['lifestyle', 'লাইফস্টাইল ', 'স্বাস্থ্য'],\n",
    "    # 'ধ্রুপদী কবিতা': ['Verses', 'কবিতা'],\n",
    "    'অন্যান্য': ['প্রবাসের খবর', 'মফস্বল', 'no category','মতামত','Verses', 'কবিতা']\n",
    "}\n",
    "\n",
    "\n",
    "# 分块读取原始语料文件，并根据类别合并规则对类别进行统一处理\n",
    "corpus_file = 'deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "output_file = 'deduplicated_mangoNews_Nums3000p_CategoryMerge.csv'\n",
    "\n",
    "chunk_size = 100000  # 设置分块大小\n",
    "\n",
    "for chunk in pd.read_csv(corpus_file, chunksize=chunk_size, low_memory=False,lineterminator=\"\\n\"):\n",
    "    print(len(chunk))\n",
    "    # 根据类别合并规则对类别进行统一处理\n",
    "    for target_category, source_categories in category_mapping.items():\n",
    "        chunk.loc[chunk['category1'].isin(source_categories), 'category1'] = target_category\n",
    "    # 将处理后的结果写入到新的 CSV 文件中\n",
    "    chunk.to_csv(output_file, mode='a', index=False, header=not os.path.exists(output_file))\n",
    "\n",
    "print(\"已将类别进行合并处理，并写入到新的 CSV 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73b72b3-e58d-4966-8767-fd548f12ce6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "0\n",
      "100000\n",
      "0\n",
      "100000\n",
      "0\n",
      "100000\n",
      "0\n",
      "100000\n",
      "0\n",
      "100000\n",
      "0\n",
      "100000\n",
      "0\n",
      "100000\n",
      "0\n",
      "100000\n",
      "0\n",
      "90000\n",
      "0\n",
      "含有 'http' 的行数量： 0\n",
      "已将不含有 'http' 的行保存到新文件中。\n"
     ]
    }
   ],
   "source": [
    "# 分块读取并统计含有 \"http\" 的行的数量，并将不含有 \"http\" 的行保存到新的文件中\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 文件路径\n",
    "# file_path = \"./deduplicated_mangoNews_Nums3000p_CategoryMerge.csv\"\n",
    "file_path = \"./deduplicated_mangoNews_Nums3000p_CategoryMerge_990000.csv\"\n",
    "output_file_path = \"./deduplicated_mangoNews_Nums3000p_CategoryMerge_990000_1.csv\"\n",
    "chunk_size = 100000  # 每个块的大小\n",
    "\n",
    "# 初始化含有 \"http\" 的行的数量\n",
    "http_rows_count = 0\n",
    "\n",
    "# 分块读取并统计含有 \"http\" 的行的数量，并将不含有 \"http\" 的行保存到新的文件中\n",
    "with pd.read_csv(file_path, chunksize=chunk_size, low_memory=False,lineterminator=\"\\n\") as reader:\n",
    "    for chunk in reader:\n",
    "        print(len(chunk))\n",
    "        # 统计含有 \"http\" 的行的数量\n",
    "        http_rows_count += chunk[chunk['category1'].str.contains(\"http\")].shape[0]\n",
    "        print(http_rows_count)\n",
    "        # 去除含有 \"http\" 的行\n",
    "        chunk = chunk[~chunk['category1'].str.contains(\"http\")]\n",
    "        \n",
    "        # 将处理后的结果追加保存到新的文件中\n",
    "        chunk.to_csv(output_file_path, mode='a', index=False, header=not os.path.exists(output_file_path))\n",
    "\n",
    "print(\"含有 'http' 的行数量：\", http_rows_count)\n",
    "print(\"已将不含有 'http' 的行保存到新文件中。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b1ec89-c59f-48db-a63a-99f129857da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "2733\n",
      "已将类别进行合并处理，并写入到新的 CSV 文件中。\n"
     ]
    }
   ],
   "source": [
    "# 对去重，类别对应语料数大于3000的语料的类别进行合并\n",
    "# 新合并规则\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# # 读取原始语料文件\n",
    "# corpus_file = 'deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "# corpus_df = pd.read_csv(corpus_file)\n",
    "\n",
    "# 定义类别合并规则\n",
    "category_mapping = {\n",
    "    # 'বাংলাদেশ': ['বাংলাদেশ', 'bangladesh'],\n",
    "    'জাতীয়': ['জাতীয়', 'national', 'দেশজুড়ে', 'দেশ', 'জাতীয়', 'সারাদেশ','বাংলাদেশ', 'bangladesh'], # 全国，孟加拉国\n",
    "    'আন্তর্জাতিক': ['আন্তর্জাতিক', 'international', 'International'],\n",
    "    # 'সংবাদ': ['সংবাদ', 'খবর', 'News'], # 新闻\n",
    "    # 'সর্বশেষ সংবাদ': ['আজকের পত্রিকা', 'সর্বশেষ সংবাদ'], # 最新动态\n",
    "    'খেলাধুলা': ['খেলাধুলা', 'sports', 'খেলা', 'খেলাধুলা ', 'ক্রিকেট', 'স্পোর্টস', 'Sports'],\n",
    "    'রাজনীতি': ['রাজনীতি', 'politics'],\n",
    "    'বিনোদন': ['বিনোদন ', 'entertainment', 'বিনোদন'],\n",
    "    'আর্কাইভ': ['আর্কাইভ', 'archive'],\n",
    "    'অর্থনীতি': ['অর্থনীতি', 'রাজধানী', 'অর্থ-বাণিজ্য', 'economics', 'অর্থ-উন্নয়ন', 'পুঁজিবাজার'],\n",
    "    # 'বৈশিষ্ট্যযুক্ত': ['Featured News', 'ফিচার'], # 特色\n",
    "    'আইন': ['অপরাধ', 'আদালত', 'আইন-বিচার', 'পুলিশ', 'আইন-বিচার ', 'অপরাধ ও দুর্নীতি'],\n",
    "    'শিক্ষা': ['শিক্ষা', 'শিক্ষা ', 'campus'],\n",
    "    'বিজ্ঞান': ['বিজ্ঞান ও তথ্যপ্রযুক্তি', 'তথ্য প্রযুক্তি'],\n",
    "    'লাইফস্টাইল': ['lifestyle', 'লাইফস্টাইল ', 'স্বাস্থ্য'],\n",
    "    # 'ধ্রুপদী কবিতা': ['Verses', 'কবিতা'],\n",
    "    'অন্যান্য': ['প্রবাসের খবর', 'মফস্বল', 'no category','মতামত','Verses', 'কবিতা','সংবাদ', 'খবর', 'News','আজকের পত্রিকা', 'সর্বশেষ সংবাদ','Featured News', 'ফিচার']  # 其他 新闻 最新动态 特色\n",
    " \n",
    "}\n",
    "\n",
    "\n",
    "# 分块读取原始语料文件，并根据类别合并规则对类别进行统一处理\n",
    "corpus_file = 'deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "output_file = 'deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv'\n",
    "\n",
    "chunk_size = 100000  # 设置分块大小\n",
    "\n",
    "for chunk in pd.read_csv(corpus_file, chunksize=chunk_size, low_memory=False,lineterminator=\"\\n\"):\n",
    "    print(len(chunk))\n",
    "    # 根据类别合并规则对类别进行统一处理\n",
    "    for target_category, source_categories in category_mapping.items():\n",
    "        chunk.loc[chunk['category1'].isin(source_categories), 'category1'] = target_category\n",
    "    # 将处理后的结果写入到新的 CSV 文件中\n",
    "    chunk.to_csv(output_file, mode='a', index=False, header=not os.path.exists(output_file))\n",
    "\n",
    "print(\"已将类别进行合并处理，并写入到新的 CSV 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e25ac87-5cf8-42e8-9e8e-d5a9e4520f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514835\n",
      "已将类别进行合并处理，并写入到新的 CSV 文件中。\n"
     ]
    }
   ],
   "source": [
    "# 对去重，类别对应语料数大于3000的语料的类别进行合并\n",
    "# 新合并规则\n",
    "# update:最新合并规则 3.5 去除国际和全国 “其他”只保留三种\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# # 读取原始语料文件\n",
    "# corpus_file = 'deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "# corpus_df = pd.read_csv(corpus_file)\n",
    "\n",
    "# 定义类别合并规则\n",
    "category_mapping = {\n",
    "    # 'বাংলাদেশ': ['বাংলাদেশ', 'bangladesh'],\n",
    "    # 'জাতীয়': ['জাতীয়', 'national', 'দেশজুড়ে', 'দেশ', 'জাতীয়', 'সারাদেশ','বাংলাদেশ', 'bangladesh'], # 全国，孟加拉国  去除\n",
    "    # 'আন্তর্জাতিক': ['আন্তর্জাতিক', 'international', 'International'],  # 国际 去除\n",
    "    # 'সংবাদ': ['সংবাদ', 'খবর', 'News'], # 新闻\n",
    "    # 'সর্বশেষ সংবাদ': ['আজকের পত্রিকা', 'সর্বশেষ সংবাদ'], # 最新动态\n",
    "    'খেলাধুলা': ['খেলাধুলা', 'sports', 'খেলা', 'খেলাধুলা ', 'ক্রিকেট', 'স্পোর্টস', 'Sports'],\n",
    "    'রাজনীতি': ['রাজনীতি', 'politics'],\n",
    "    'বিনোদন': ['বিনোদন ', 'entertainment', 'বিনোদন'],\n",
    "    'আর্কাইভ': ['আর্কাইভ', 'archive'],\n",
    "    'অর্থনীতি': ['অর্থনীতি', 'রাজধানী', 'অর্থ-বাণিজ্য', 'economics', 'অর্থ-উন্নয়ন', 'পুঁজিবাজার'],\n",
    "    # 'বৈশিষ্ট্যযুক্ত': ['Featured News', 'ফিচার'], # 特色\n",
    "    'আইন': ['অপরাধ', 'আদালত', 'আইন-বিচার', 'পুলিশ', 'আইন-বিচার ', 'অপরাধ ও দুর্নীতি'],\n",
    "    'শিক্ষা': ['শিক্ষা', 'শিক্ষা ', 'campus'],\n",
    "    'বিজ্ঞান': ['বিজ্ঞান ও তথ্যপ্রযুক্তি', 'তথ্য প্রযুক্তি'],\n",
    "    'লাইফস্টাইল': ['lifestyle', 'লাইফস্টাইল ', 'স্বাস্থ্য'],\n",
    "    # 'ধ্রুপদী কবিতা': ['Verses', 'কবিতা'],\n",
    "    # 'অন্যান্য': ['প্রবাসের খবর', 'মফস্বল', 'no category','মতামত','Verses', 'কবিতা','সংবাদ', 'খবর', 'News','আজকের পত্রিকা', 'সর্বশেষ সংবাদ','Featured News', 'ফিচার']  # 其他 新闻 最新动态 特色\n",
    "    'অন্যান্য': [ 'মতামত','Verses', 'কবিতা']  # 其他 新  37、意见观点 44、经文（Verses） 45、诗\n",
    "\n",
    "}\n",
    "# 'খেলাধুলা','রাজনীতি','বিনোদন','আর্কাইভ','আইন','শিক্ষা','বিজ্ঞান','লাইফস্টাইল','অন্যান্য'\n",
    "allowed_categories = ['খেলাধুলা','রাজনীতি','বিনোদন','আর্কাইভ','অর্থনীতি','আইন','শিক্ষা','বিজ্ঞান','লাইফস্টাইল','অন্যান্য']\n",
    "\n",
    "\n",
    "# 分块读取原始语料文件，并根据类别合并规则对类别进行统一处理\n",
    "corpus_file = './datasets_FIX/FIX_deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "output_file = './datasets_FIX/FIX_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv'\n",
    "\n",
    "# chunk_size = 100000  # 设置分块大小\n",
    "\n",
    "df = pd.read_csv(corpus_file, low_memory=False,lineterminator=\"\\n\")\n",
    "print(len(df))\n",
    "\n",
    "for target_category, source_categories in category_mapping.items():\n",
    "    df.loc[df['category1'].isin(source_categories), 'category1'] = target_category\n",
    "filtered_df = df[df['category1'].isin(allowed_categories)]\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "    \n",
    "# for chunk in pd.read_csv(corpus_file, chunksize=chunk_size, low_memory=False,lineterminator=\"\\n\"):\n",
    "#     print(len(chunk))\n",
    "#     # 根据类别合并规则对类别进行统一处理\n",
    "#     for target_category, source_categories in category_mapping.items():\n",
    "#         chunk.loc[chunk['category1'].isin(source_categories), 'category1'] = target_category\n",
    "#     # 将处理后的结果写入到新的 CSV 文件中\n",
    "    \n",
    "#     filtered_df = df[df['category1'].isin(allowed_categories)]\n",
    "\n",
    "#     chunk.to_csv(output_file, mode='a', index=False, header=not os.path.exists(output_file))\n",
    "\n",
    "print(\"已将类别进行合并处理，并写入到新的 CSV 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e324062-b448-4ab7-9cc6-c794357ae408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514835\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "已将类别进行合并处理，并写入到新的 CSV 文件中。\n"
     ]
    }
   ],
   "source": [
    "# 对去重，类别对应语料数大于3000的语料的类别进行合并\n",
    "# 新合并规则\n",
    "# update:最新合并规则 3.5 去除国际和全国 “其他”只保留三种\n",
    "# update:最新合并规则 3.7 去除“档案”类\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# # 读取原始语料文件\n",
    "# corpus_file = 'deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "# corpus_df = pd.read_csv(corpus_file)\n",
    "\n",
    "# 定义类别合并规则\n",
    "category_mapping = {\n",
    "    # 'বাংলাদেশ': ['বাংলাদেশ', 'bangladesh'],\n",
    "    # 'জাতীয়': ['জাতীয়', 'national', 'দেশজুড়ে', 'দেশ', 'জাতীয়', 'সারাদেশ','বাংলাদেশ', 'bangladesh'], # 全国，孟加拉国  去除\n",
    "    # 'আন্তর্জাতিক': ['আন্তর্জাতিক', 'international', 'International'],  # 国际 去除\n",
    "    # 'সংবাদ': ['সংবাদ', 'খবর', 'News'], # 新闻\n",
    "    # 'সর্বশেষ সংবাদ': ['আজকের পত্রিকা', 'সর্বশেষ সংবাদ'], # 最新动态\n",
    "    'খেলাধুলা': ['খেলাধুলা', 'sports', 'খেলা', 'খেলাধুলা ', 'ক্রিকেট', 'স্পোর্টস', 'Sports'],\n",
    "    'রাজনীতি': ['রাজনীতি', 'politics'],\n",
    "    'বিনোদন': ['বিনোদন ', 'entertainment', 'বিনোদন'],\n",
    "    'আর্কাইভ': ['আর্কাইভ', 'archive'],\n",
    "    'অর্থনীতি': ['অর্থনীতি', 'রাজধানী', 'অর্থ-বাণিজ্য', 'economics', 'অর্থ-উন্নয়ন', 'পুঁজিবাজার'],\n",
    "    # 'বৈশিষ্ট্যযুক্ত': ['Featured News', 'ফিচার'], # 特色\n",
    "    'আইন': ['অপরাধ', 'আদালত', 'আইন-বিচার', 'পুলিশ', 'আইন-বিচার ', 'অপরাধ ও দুর্নীতি'],\n",
    "    'শিক্ষা': ['শিক্ষা', 'শিক্ষা ', 'campus'],\n",
    "    'বিজ্ঞান': ['বিজ্ঞান ও তথ্যপ্রযুক্তি', 'তথ্য প্রযুক্তি'],\n",
    "    'লাইফস্টাইল': ['lifestyle', 'লাইফস্টাইল ', 'স্বাস্থ্য'],\n",
    "    # 'ধ্রুপদী কবিতা': ['Verses', 'কবিতা'],\n",
    "    # 'অন্যান্য': ['প্রবাসের খবর', 'মফস্বল', 'no category','মতামত','Verses', 'কবিতা','সংবাদ', 'খবর', 'News','আজকের পত্রিকা', 'সর্বশেষ সংবাদ','Featured News', 'ফিচার']  # 其他 新闻 最新动态 特色\n",
    "    'অন্যান্য': [ 'মতামত','Verses', 'কবিতা']  # 其他 新  37、意见观点 44、经文（Verses） 45、诗\n",
    "\n",
    "}\n",
    "# 'খেলাধুলা','রাজনীতি','বিনোদন','আর্কাইভ','আইন','শিক্ষা','বিজ্ঞান','লাইফস্টাইল','অন্যান্য'\n",
    "# allowed_categories = ['体育','政治','娱乐','档案','经济','法律','教育','科学','生活方式','其他']\n",
    "# allowed_categories = ['খেলাধুলা','রাজনীতি','বিনোদন','আর্কাইভ','অর্থনীতি','আইন','শিক্ষা','বিজ্ঞান','লাইফস্টাইল','অন্যান্য']\n",
    "\n",
    "# update：3.6\n",
    "# allowed_categories = ['体育','政治','娱乐','经济','法律','教育','科学','生活方式','其他']\n",
    "allowed_categories = ['খেলাধুলা','রাজনীতি','বিনোদন','অর্থনীতি','আইন','শিক্ষা','বিজ্ঞান','লাইফস্টাইল','অন্যান্য']\n",
    "\n",
    "# 分块读取原始语料文件，并根据类别合并规则对类别进行统一处理\n",
    "corpus_file = './datasets_FIX2/FIX_deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "output_file = './datasets_FIX2/FIX2_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv'\n",
    "\n",
    "# chunk_size = 100000  # 设置分块大小\n",
    "\n",
    "df = pd.read_csv(corpus_file, low_memory=False,lineterminator=\"\\n\")\n",
    "print(len(df))\n",
    "cnt = 0\n",
    "for target_category, source_categories in category_mapping.items():\n",
    "    print(cnt)\n",
    "    cnt+=1\n",
    "    df.loc[df['category1'].isin(source_categories), 'category1'] = target_category\n",
    "filtered_df = df[df['category1'].isin(allowed_categories)]\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "    \n",
    "# for chunk in pd.read_csv(corpus_file, chunksize=chunk_size, low_memory=False,lineterminator=\"\\n\"):\n",
    "#     print(len(chunk))\n",
    "#     # 根据类别合并规则对类别进行统一处理\n",
    "#     for target_category, source_categories in category_mapping.items():\n",
    "#         chunk.loc[chunk['category1'].isin(source_categories), 'category1'] = target_category\n",
    "#     # 将处理后的结果写入到新的 CSV 文件中\n",
    "    \n",
    "#     filtered_df = df[df['category1'].isin(allowed_categories)]\n",
    "\n",
    "#     chunk.to_csv(output_file, mode='a', index=False, header=not os.path.exists(output_file))\n",
    "\n",
    "print(\"已将类别进行合并处理，并写入到新的 CSV 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dccea88a-7941-445b-972c-d361083875a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514835\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "已将类别进行合并处理，并写入到新的 CSV 文件中。\n"
     ]
    }
   ],
   "source": [
    "# 对去重，类别对应语料数大于3000的语料的类别进行合并\n",
    "# 新合并规则\n",
    "# update:最新合并规则 3.5 去除国际和全国 “其他”只保留三种\n",
    "# update:最新合并规则 3.7 去除“档案”类 FIX2  使用这个！\n",
    "# update:最新合并规则 3.8 \"其他”只保留意见观点 FIX3\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# # 读取原始语料文件\n",
    "# corpus_file = 'deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "# corpus_df = pd.read_csv(corpus_file)\n",
    "\n",
    "# 定义类别合并规则\n",
    "category_mapping = {\n",
    "    # 'বাংলাদেশ': ['বাংলাদেশ', 'bangladesh'],\n",
    "    # 'জাতীয়': ['জাতীয়', 'national', 'দেশজুড়ে', 'দেশ', 'জাতীয়', 'সারাদেশ','বাংলাদেশ', 'bangladesh'], # 全国，孟加拉国  去除\n",
    "    # 'আন্তর্জাতিক': ['আন্তর্জাতিক', 'international', 'International'],  # 国际 去除\n",
    "    # 'সংবাদ': ['সংবাদ', 'খবর', 'News'], # 新闻\n",
    "    # 'সর্বশেষ সংবাদ': ['আজকের পত্রিকা', 'সর্বশেষ সংবাদ'], # 最新动态\n",
    "    'খেলাধুলা': ['খেলাধুলা', 'sports', 'খেলা', 'খেলাধুলা ', 'ক্রিকেট', 'স্পোর্টস', 'Sports'],\n",
    "    'রাজনীতি': ['রাজনীতি', 'politics'],\n",
    "    'বিনোদন': ['বিনোদন ', 'entertainment', 'বিনোদন'],\n",
    "    'আর্কাইভ': ['আর্কাইভ', 'archive'],\n",
    "    'অর্থনীতি': ['অর্থনীতি', 'রাজধানী', 'অর্থ-বাণিজ্য', 'economics', 'অর্থ-উন্নয়ন', 'পুঁজিবাজার'],\n",
    "    # 'বৈশিষ্ট্যযুক্ত': ['Featured News', 'ফিচার'], # 特色\n",
    "    'আইন': ['অপরাধ', 'আদালত', 'আইন-বিচার', 'পুলিশ', 'আইন-বিচার ', 'অপরাধ ও দুর্নীতি'],\n",
    "    'শিক্ষা': ['শিক্ষা', 'শিক্ষা ', 'campus'],\n",
    "    'বিজ্ঞান': ['বিজ্ঞান ও তথ্যপ্রযুক্তি', 'তথ্য প্রযুক্তি'],\n",
    "    'লাইফস্টাইল': ['lifestyle', 'লাইফস্টাইল ', 'স্বাস্থ্য'],\n",
    "    # 'ধ্রুপদী কবিতা': ['Verses', 'কবিতা'],\n",
    "    # 'অন্যান্য': ['প্রবাসের খবর', 'মফস্বল', 'no category','মতামত','Verses', 'কবিতা','সংবাদ', 'খবর', 'News','আজকের পত্রিকা', 'সর্বশেষ সংবাদ','Featured News', 'ফিচার']  # 其他 新闻 最新动态 特色\n",
    "    # 'অন্যান্য': [ 'মতামত','Verses', 'কবিতা']  # 其他 新  37、意见观点 44、经文（Verses） 45、诗\n",
    "    'অন্যান্য': [ 'মতামত']  # 其他 新  37、意见观点 \n",
    "\n",
    "\n",
    "}\n",
    "# 'খেলাধুলা','রাজনীতি','বিনোদন','আর্কাইভ','আইন','শিক্ষা','বিজ্ঞান','লাইফস্টাইল','অন্যান্য'\n",
    "# allowed_categories = ['体育','政治','娱乐','档案','经济','法律','教育','科学','生活方式','其他']\n",
    "# allowed_categories = ['খেলাধুলা','রাজনীতি','বিনোদন','আর্কাইভ','অর্থনীতি','আইন','শিক্ষা','বিজ্ঞান','লাইফস্টাইল','অন্যান্য']\n",
    "\n",
    "# update：3.6\n",
    "# allowed_categories = ['体育','政治','娱乐','经济','法律','教育','科学','生活方式','其他']\n",
    "allowed_categories = ['খেলাধুলা','রাজনীতি','বিনোদন','অর্থনীতি','আইন','শিক্ষা','বিজ্ঞান','লাইফস্টাইল','অন্যান্য']\n",
    "\n",
    "# 分块读取原始语料文件，并根据类别合并规则对类别进行统一处理\n",
    "corpus_file = './datasets_FIX2/FIX_deduplicated_mangoNews_Nums3000p.csv'  # 替换为你的原始语料文件路径\n",
    "output_file = './datasets_FIX3/FIX3_deduplicated_mangoNews_Nums3000p_CategoryMerge_new.csv'\n",
    "\n",
    "# chunk_size = 100000  # 设置分块大小\n",
    "\n",
    "df = pd.read_csv(corpus_file, low_memory=False,lineterminator=\"\\n\")\n",
    "print(len(df))\n",
    "cnt = 0\n",
    "for target_category, source_categories in category_mapping.items():\n",
    "    print(cnt)\n",
    "    cnt+=1\n",
    "    df.loc[df['category1'].isin(source_categories), 'category1'] = target_category\n",
    "filtered_df = df[df['category1'].isin(allowed_categories)]\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "    \n",
    "# for chunk in pd.read_csv(corpus_file, chunksize=chunk_size, low_memory=False,lineterminator=\"\\n\"):\n",
    "#     print(len(chunk))\n",
    "#     # 根据类别合并规则对类别进行统一处理\n",
    "#     for target_category, source_categories in category_mapping.items():\n",
    "#         chunk.loc[chunk['category1'].isin(source_categories), 'category1'] = target_category\n",
    "#     # 将处理后的结果写入到新的 CSV 文件中\n",
    "    \n",
    "#     filtered_df = df[df['category1'].isin(allowed_categories)]\n",
    "\n",
    "#     chunk.to_csv(output_file, mode='a', index=False, header=not os.path.exists(output_file))\n",
    "\n",
    "print(\"已将类别进行合并处理，并写入到新的 CSV 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885bcb39-a736-4b0d-8105-9187b78a30af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不同的元素： set()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取第一个CSV文件\n",
    "df1 = pd.read_csv(\"./res_files_FIX/FIX_deduplicated_mangoNews_Nums3000p_counts_all.csv\")\n",
    "category1_1 = sorted(df1[\"category1\"].tolist())\n",
    "\n",
    "# 读取第二个CSV文件\n",
    "df2 = pd.read_csv(\"./res_files/category_counts_all_new_Nums3000p.csv\")\n",
    "category1_2 = sorted(df2[\"category1\"].tolist())\n",
    "\n",
    "# 找到不同的元素\n",
    "diff_elements = set(category1_1) ^ set(category1_2)\n",
    "\n",
    "# 打印出不同的元素\n",
    "print(\"不同的元素：\", diff_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9bc10-0329-4955-8cdc-a51ecaeaa881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-default",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
